{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ATLAS Math Reasoning Demo\n\nThis notebook demonstrates the ATLAS two-pass inference protocol improving math problem solving accuracy.\n\n## Overview\n\nATLAS uses a teacher model to guide student models through:\n1. **Diagnostic Probing**: Teacher assesses student capability\n2. **Adaptive Learning**: Teacher provides targeted guidance based on assessment\n3. **Enhanced Response**: Student generates improved solution using guidance\n\nThe system is designed to improve performance while preventing degradation through zero-reward for harmful interventions."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    if not os.path.exists('/content/ATLAS'):\n",
    "        !git clone https://github.com/Arc-Computer/ATLAS.git /content/ATLAS\n",
    "    \n",
    "    os.chdir('/content/ATLAS/examples')\n",
    "    \n",
    "    if '/content/ATLAS/examples' not in sys.path:\n",
    "        sys.path.append('/content/ATLAS/examples')\n",
    "    \n",
    "    !pip install -q transformers torch accelerate datasets matplotlib pandas numpy\n",
    "    print(\"✓ Repository cloned and packages installed for Google Colab\")\n",
    "    print(f\"✓ Working directory: {os.getcwd()}\")\n",
    "else:\n",
    "    if not os.path.exists('utils'):\n",
    "        print(\"⚠️  Warning: 'utils' directory not found. Please run from the examples/ directory\")\n",
    "    print(\"Using local environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils.atlas_inference import ATLASInference, load_atlas_models\n",
    "from utils.evaluation import calculate_metrics, extract_numerical_answer\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_STUDENT_MODEL = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "DEFAULT_TEACHER_THINKING = \"Arc-Intelligence/ATLAS-8B-Thinking\"\n",
    "DEFAULT_TEACHER_INSTRUCT = \"Arc-Intelligence/ATLAS-8B-Instruct\"\n",
    "\n",
    "PROBE_TOKEN_LIMIT = 150  \n",
    "LEARNING_RESPONSE_LIMIT = 500 \n",
    "STUDENT_RESPONSE_LIMIT = 1000 \n",
    "\n",
    "CAPABILITY_HIGH_THRESHOLD = 4\n",
    "CAPABILITY_MEDIUM_THRESHOLD = 2\n",
    "\n",
    "MIN_GPU_MEMORY_GB = 12\n",
    "RECOMMENDED_GPU_MEMORY_GB = 16\n",
    "\n",
    "DEFAULT_NUM_SAMPLES = 20\n",
    "\n",
    "print(\"Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atlas_teach_dataset(split: str = \"train\", num_samples: Optional[int] = 20) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load Arc-Intelligence/Arc-ATLAS-Teach-v0 dataset.\"\"\"\n",
    "    print(\"Loading Arc-Intelligence/Arc-ATLAS-Teach-v0 dataset...\")\n",
    "    \n",
    "    try:\n",
    "        from huggingface_hub import hf_hub_download\n",
    "        \n",
    "        # Download the RL training file\n",
    "        file_path = hf_hub_download(\n",
    "            repo_id=\"Arc-Intelligence/Arc-ATLAS-Teach-v0\",\n",
    "            filename=\"training/rl.jsonl\",\n",
    "            repo_type=\"dataset\"\n",
    "        )\n",
    "        \n",
    "        # Load the JSONL file\n",
    "        problems = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    item = json.loads(line)\n",
    "                    \n",
    "                    problem_text = item.get(\"prompt\", \"\")\n",
    "                    ground_truth = item.get(\"ground_truth\", \"\")\n",
    "                    \n",
    "                    if problem_text:\n",
    "                        problem_dict = {\n",
    "                            \"problem\": problem_text,\n",
    "                            \"solution\": ground_truth,\n",
    "                            \"source\": \"Arc-ATLAS-Teach-v0\",\n",
    "                            \"problem_id\": item.get(\"problem_id\", \"\"),\n",
    "                            \"student_level\": item.get(\"student_level\", \"\"),\n",
    "                            \"baseline_score\": item.get(\"baseline_score\", 0),\n",
    "                            \"with_teaching_score\": item.get(\"with_teaching_score\", 0),\n",
    "                            \"teaching\": item.get(\"teaching\", \"\"),\n",
    "                            \"reward\": item.get(\"reward\", 0)\n",
    "                        }\n",
    "                        \n",
    "                        # Extract numerical answer\n",
    "                        if ground_truth:\n",
    "                            numbers = re.findall(r\"[-+]?\\d*\\.?\\d+\", str(ground_truth))\n",
    "                            if numbers:\n",
    "                                try:\n",
    "                                    problem_dict[\"answer\"] = float(numbers[-1])\n",
    "                                except:\n",
    "                                    pass\n",
    "                        \n",
    "                        problems.append(problem_dict)\n",
    "        \n",
    "        # Sample if requested\n",
    "        if num_samples and len(problems) > num_samples:\n",
    "            problems = random.sample(problems, num_samples)\n",
    "        \n",
    "        print(f\"Loaded {len(problems)} problems from Arc-ATLAS-Teach dataset\")\n",
    "        return problems\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Arc-ATLAS-Teach dataset: {e}\")\n",
    "        print(\"Falling back to sample problems...\")\n",
    "        return get_sample_math_problems()\n",
    "\n",
    "def get_sample_math_problems() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Fallback sample math problems.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"problem\": \"Sarah has 24 apples. She gives 1/3 of them to her brother and 1/4 of the remaining apples to her sister. How many apples does Sarah have left?\",\n",
    "            \"answer\": 12,\n",
    "            \"solution\": \"Sarah starts with 24 apples. She gives 1/3 to her brother: 24 × 1/3 = 8 apples. Remaining: 24 - 8 = 16 apples. She gives 1/4 of remaining to her sister: 16 × 1/4 = 4 apples. Final amount: 16 - 4 = 12 apples.\",\n",
    "            \"source\": \"sample\"\n",
    "        },\n",
    "        {\n",
    "            \"problem\": \"A train travels 120 miles in 2 hours. If it maintains the same speed, how far will it travel in 5 hours?\",\n",
    "            \"answer\": 300,\n",
    "            \"solution\": \"Speed = Distance ÷ Time = 120 miles ÷ 2 hours = 60 miles per hour. Distance in 5 hours = Speed × Time = 60 mph × 5 hours = 300 miles.\",\n",
    "            \"source\": \"sample\"\n",
    "        },\n",
    "        {\n",
    "            \"problem\": \"The sum of two consecutive even numbers is 46. What are the two numbers?\",\n",
    "            \"answer\": \"22 and 24\",\n",
    "            \"solution\": \"Let the first even number be x. The next consecutive even number is x + 2. Sum: x + (x + 2) = 46. Solving: 2x + 2 = 46, so 2x = 44, and x = 22. The two numbers are 22 and 24.\",\n",
    "            \"source\": \"sample\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading math problems...\\n\")\n",
    "\n",
    "try:\n",
    "    problems = load_atlas_teach_dataset(num_samples=DEFAULT_NUM_SAMPLES)\n",
    "    print(f\"Loaded {len(problems)} problems\")\n",
    "except Exception as e:\n",
    "    print(f\"Dataset loading failed: {e}\")\n",
    "    print(\"Using sample problems...\")\n",
    "    problems = get_sample_math_problems()\n",
    "\n",
    "print(f\"\\nSample problem:\")\n",
    "print(f\"Problem: {problems[0]['problem'][:200]}...\")\n",
    "print(f\"Answer: {problems[0].get('answer', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    if gpu_memory < MIN_GPU_MEMORY_GB:\n",
    "        print(f\"Warning: GPU memory ({gpu_memory:.1f} GB) below recommended {MIN_GPU_MEMORY_GB} GB\")\n",
    "        print(\"   Consider using 8-bit quantization or smaller models\")\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU (will be slower)\")\n",
    "    print(\"   For better performance, use Google Colab with GPU runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading models...\")\n",
    "print(f\"Student: {DEFAULT_STUDENT_MODEL}\")\n",
    "print(f\"Teacher: {DEFAULT_TEACHER_THINKING}\\n\")\n",
    "\n",
    "try:\n",
    "    reasoning_atlas, _ = load_atlas_models(\n",
    "        student_model_name=DEFAULT_STUDENT_MODEL,\n",
    "        teacher_thinking_name=DEFAULT_TEACHER_THINKING,\n",
    "        teacher_instruct_name=DEFAULT_TEACHER_INSTRUCT,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    "    )\n",
    "    \n",
    "    atlas = reasoning_atlas\n",
    "    print(\"✓ Models loaded successfully\")\n",
    "    print(f\"✓ Using device: {device}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check internet connection\")\n",
    "    print(\"2. Verify HuggingFace access (run: huggingface-cli login)\")\n",
    "    print(\"3. Check GPU memory (need ~12GB for both models)\")\n",
    "    print(\"4. Try reducing batch size or using CPU\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ATLAS Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "print(\"\\nRunning ATLAS protocol on problems...\\n\")\n",
    "\n",
    "for i, problem in enumerate(problems[:3]):  # Focus on 3 high-quality examples\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Problem {i+1}/{min(3, len(problems))}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        result = atlas.run_full_protocol(problem[\"problem\"])\n",
    "        \n",
    "        result[\"problem_id\"] = i\n",
    "        result[\"ground_truth\"] = problem.get(\"answer\")\n",
    "        result[\"problem_text\"] = problem[\"problem\"]\n",
    "        results.append(result)\n",
    "        \n",
    "        # Show the actual diagnostic and teaching process\n",
    "        print(f\"\\nPROBLEM: {problem['problem'][:200]}...\")\n",
    "        \n",
    "        print(f\"\\nDIAGNOSTIC ASSESSMENT:\")\n",
    "        print(f\"Capability Score: {result['diagnostic']['capability_score']}/5\")\n",
    "        print(f\"Strategy Selected: {result['learning']['strategy']}\")\n",
    "        \n",
    "        print(f\"\\nCompleted\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Completed {len(results)} problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results:\n",
    "    metrics = calculate_metrics(\n",
    "        problems[:len(results)], \n",
    "        results, \n",
    "        task_type=\"math\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Baseline Accuracy: {metrics.get('baseline_accuracy', 0):.1%}\")\n",
    "    print(f\"With ATLAS:        {metrics.get('guided_accuracy', 0):.1%}\")\n",
    "    print(f\"Improvement:       +{metrics.get('improvement_percentage', 0):.1f}%\")\n",
    "    print(f\"Improvements:      {metrics.get('improvements', 0)} problems\")\n",
    "    print(f\"Degradations:      {metrics.get('degradations', 0)} problems\")\n",
    "    print(f\"Non-degradation:   {metrics.get('non_degradation_rate', 0):.1%}\")\n",
    "    print(\"=\" * 50)\n",
    "else:\n",
    "    print(\"No results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results:\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Example {i+1}: {problems[i]['problem'][:100]}...\")\n",
    "        print('='*80)\n",
    "        \n",
    "        print(\"\\nSTUDENT ALONE (Baseline):\")\n",
    "        print(result['baseline_response'])\n",
    "        \n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(\"PASS 1: DIAGNOSTIC PROBING\")\n",
    "        print(f\"Capability: {result['diagnostic']['capability_score']}/5 → {result['learning']['strategy']} intervention\")\n",
    "        \n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(\"PASS 2: ADAPTIVE TEACHING\")\n",
    "        print(result['learning']['learning_guidance'][:500])\n",
    "        \n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(\"STUDENT WITH ATLAS:\")\n",
    "        print(result['guided_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_problem(problem_text: str):\n",
    "    \"\"\"Test ATLAS with a custom math problem.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Testing custom problem\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nProblem: {problem_text}\\n\")\n",
    "    \n",
    "    result = atlas.run_full_protocol(problem_text)\n",
    "    \n",
    "    print(\"\\nStudent Response (Alone):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(result['baseline_response'])\n",
    "    \n",
    "    print(\"\\nTeacher Guidance:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Strategy: {result['learning']['strategy']}\")\n",
    "    print(f\"Guidance: {result['learning']['response'][:200]}...\")\n",
    "    \n",
    "    print(\"\\nStudent Response (With ATLAS):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(result['guided_response'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "custom_problem = \"A store offers a 20% discount on all items. If a jacket originally costs $80, how much will it cost after the discount?\"\n",
    "custom_result = test_custom_problem(custom_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Efficiency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for further analysis\n",
    "if results:\n",
    "    output_file = \"atlas_math_results.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump({\n",
    "            \"metrics\": metrics,\n",
    "            \"results\": results,\n",
    "            \"config\": {\n",
    "                \"student_model\": DEFAULT_STUDENT_MODEL,\n",
    "                \"teacher_model\": DEFAULT_TEACHER_THINKING,\n",
    "                \"num_problems\": len(results)\n",
    "            }\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nResults saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}