{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atlas-math-demo-header"
   },
   "source": [
    "# ATLAS Math Reasoning Demo\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Arc-Intelligence/RCL/blob/main/examples/math_reasoning_demo.ipynb)\n",
    "\n",
    "## üéØ Goal: See 15.7% Accuracy Improvement in < 5 Minutes\n",
    "\n",
    "This notebook demonstrates ATLAS's two-pass inference protocol:\n",
    "1. **Diagnostic Probing** (‚â§50 tokens): Teacher assesses student capability  \n",
    "2. **Adaptive Teaching**: Conditional guidance based on diagnosed strength\n",
    "\n",
    "**Models Used:**\n",
    "- **Student**: Qwen/Qwen3-4B-Instruct-2507\n",
    "- **Teacher**: ATLAS-8B-Thinking\n",
    "- **Dataset**: Arc-Intelligence/Arc-ATLAS-Teach-v0 or Big-Math-RL subset\n",
    "\n",
    "**Hardware Requirements:** Single GPU (T4/A100), 12-16GB RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-environment"
   },
   "outputs": [],
   "source": [
    "# Install dependencies (Colab)\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q transformers datasets torch accelerate\n",
    "    !pip install -q matplotlib seaborn pandas numpy\n",
    "    \n",
    "    # Clone repository for utils\n",
    "    !git clone -q https://github.com/Arc-Intelligence/RCL.git\n",
    "    sys.path.append('/content/RCL/examples')\n",
    "else:\n",
    "    # Local development\n",
    "    sys.path.append('.')\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import ATLAS utilities\n",
    "from utils.atlas_inference import ATLASInference, load_atlas_models\n",
    "from utils.evaluation import calculate_metrics\n",
    "from utils.visualization import plot_comparison, display_results_table, show_example_comparisons\n",
    "from data.load_datasets import load_atlas_teach_dataset, load_bigmath_dataset\n",
    "\n",
    "print(\"üìö Libraries imported successfully\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-dataset"
   },
   "outputs": [],
   "source": [
    "# Load math problems from HuggingFace datasets\n",
    "print(\"Loading math problems from HuggingFace...\\n\")\n",
    "\n",
    "try:\n",
    "    # Try Arc-ATLAS-Teach dataset first\n",
    "    problems = load_atlas_teach_dataset(num_samples=20)\n",
    "    print(f\"‚úÖ Loaded {len(problems)} problems from Arc-ATLAS-Teach dataset\")\nexcept Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Arc-ATLAS-Teach dataset failed: {e}\")\n",
    "    try:\n",
    "        # Fallback to Big-Math dataset\n",
    "        problems = load_bigmath_dataset(num_samples=20)\n",
    "        print(f\"‚úÖ Loaded {len(problems)} problems from Big-Math dataset\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ö†Ô∏è  Big-Math dataset also failed: {e2}\")\n",
    "        print(\"Using fallback sample problems...\")\n",
    "        from data.load_datasets import get_sample_math_problems\n",
    "        problems = get_sample_math_problems()\n",
    "\n",
    "print(f\"\\nüìù Dataset Summary:\")\n",
    "print(f\"   Total problems: {len(problems)}\")\n",
    "print(f\"   Source: {problems[0].get('source', 'unknown')}\")\n",
    "\n",
    "# Show sample problem\n",
    "sample = problems[0]\n",
    "print(f\"\\nüîç Sample Problem:\")\n",
    "print(f\"Problem: {sample['problem'][:200]}{'...' if len(sample['problem']) > 200 else ''}\")\n",
    "print(f\"Expected: {sample.get('answer', sample.get('solution', 'N/A'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Load Models\n",
    "\n",
    "Loading the student model (Qwen3-4B-Instruct-2507) and ATLAS teacher (ATLAS-8B-Thinking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-models"
   },
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading ATLAS models...\\n\")\n",
    "\n",
    "# Load models with memory optimization\n",
    "device_map = \"auto\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "try:\n",
    "    reasoning_atlas, _ = load_atlas_models(\n",
    "        student_model_name=\"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "        teacher_thinking_name=\"Arc-Intelligence/ATLAS-8B-Thinking\", \n",
    "        device_map=device_map,\n",
    "        torch_dtype=torch_dtype\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Models loaded successfully!\")\n",
    "    \n",
    "    # Memory check\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.memory_allocated() / 1024**3\n",
    "        memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"üìä GPU Memory: {memory_used:.1f}GB / {memory_total:.1f}GB ({memory_used/memory_total*100:.1f}%)\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"‚ùå Error loading models: {e}\")\n",
    "    print(\"This demo requires GPU access. Please ensure you have:\")\n",
    "    print(\"- GPU runtime enabled in Colab\")\n",
    "    print(\"- Sufficient GPU memory (12GB+ recommended)\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† ATLAS Two-Pass Protocol in Action\n",
    "\n",
    "Let's see how ATLAS works step by step with a single example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo-single-example"
   },
   "outputs": [],
   "source": [
    "# Demo with single problem\n",
    "demo_problem = problems[0]\n",
    "print(f\"üéØ Demo Problem: {demo_problem['problem']}\\n\")\n",
    "\n",
    "print(\"üîç Phase 1: Diagnostic Probing\")\n",
    "diagnostic_result = reasoning_atlas.diagnostic_probe(demo_problem['problem'])\n",
    "print(f\"Capability Score: {diagnostic_result['capability_score']}/5\")\n",
    "print(f\"Teaching Strategy: {diagnostic_result['teaching_strategy']}\")\n",
    "print(f\"Assessment: {diagnostic_result['probe_response'][:200]}...\\n\")\n",
    "\n",
    "print(\"üéì Phase 2: Adaptive Teaching\")\n",
    "teaching_result = reasoning_atlas.adaptive_teaching(demo_problem['problem'], diagnostic_result)\n",
    "print(f\"Teaching Guidance: {teaching_result['teaching_guidance'][:300]}...\\n\")\n",
    "\n",
    "print(\"üë§ Student Baseline Response:\")\n",
    "baseline_response = reasoning_atlas.generate_student_response(demo_problem['problem'])\n",
    "print(f\"{baseline_response[:300]}...\\n\")\n",
    "\n",
    "print(\"‚ú® Student + Teacher Response:\")\n",
    "guided_response = reasoning_atlas.generate_student_response(\n",
    "    demo_problem['problem'], \n",
    "    teaching_result['teaching_guidance']\n",
    ")\n",
    "print(f\"{guided_response[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Full Evaluation: Baseline vs ATLAS\n",
    "\n",
    "Now let's run the complete evaluation across all problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "full-evaluation"
   },
   "outputs": [],
   "source": [
    "print(f\"üöÄ Running full evaluation on {len(problems)} problems...\\n\")\n",
    "\n",
    "# Run ATLAS protocol on all problems\n",
    "results = []\n",
    "for i, problem in enumerate(problems):\n",
    "    print(f\"Processing problem {i+1}/{len(problems)}...\", end=\"\\r\")\n",
    "    \n",
    "    try:\n",
    "        result = reasoning_atlas.run_full_protocol(problem['problem'])\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Error on problem {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation complete! Processed {len(results)} problems successfully.\")\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "print(\"\\nüìà Calculating performance metrics...\")\n",
    "metrics = calculate_metrics(problems[:len(results)], results, task_type=\"math\")\n",
    "\n",
    "print(f\"\\nüéØ Key Results:\")\n",
    "print(f\"   Baseline Accuracy: {metrics['baseline_accuracy']:.1%}\")\n",
    "print(f\"   ATLAS Accuracy: {metrics['guided_accuracy']:.1%}\")\n",
    "print(f\"   Improvement: +{metrics['improvement_percentage']:.1f}%\")\n",
    "print(f\"   Problems Improved: {metrics['improvements']}\")\n",
    "print(f\"   Problems Degraded: {metrics['degradations']}\")\n",
    "print(f\"   Non-Degradation Rate: {metrics['non_degradation_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Performance Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-results"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive performance plots\n",
    "plot_comparison(metrics, task_type=\"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-table"
   },
   "outputs": [],
   "source": [
    "# Display detailed results table\n",
    "display_results_table(metrics, task_type=\"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-comparisons"
   },
   "outputs": [],
   "source": [
    "# Show example comparisons\n",
    "show_example_comparisons(problems[:len(results)], results, num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Diagnostic Analysis\n",
    "\n",
    "Understanding how ATLAS adapts its teaching strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diagnostic-analysis"
   },
   "outputs": [],
   "source": [
    "from utils.visualization import create_diagnostic_analysis\n",
    "\n",
    "# Analyze diagnostic probing results\n",
    "create_diagnostic_analysis(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "Based on this evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary-insights"
   },
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "baseline_acc = metrics['baseline_accuracy'] * 100\n",
    "atlas_acc = metrics['guided_accuracy'] * 100\n",
    "improvement = metrics['improvement_percentage']\n",
    "ndr = metrics['non_degradation_rate'] * 100\n",
    "\n",
    "summary_html = f\"\"\"\n",
    "<div style='background-color: #f0f8ff; padding: 20px; border-radius: 10px; border-left: 5px solid #4CAF50;'>\n",
    "    <h3 style='color: #2E8B57; margin-top: 0;'>üéØ ATLAS Performance Summary</h3>\n",
    "    \n",
    "    <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 15px 0;'>\n",
    "        <div>\n",
    "            <h4 style='margin: 0; color: #4169E1;'>üìä Accuracy Results</h4>\n",
    "            <p style='margin: 5px 0;'><strong>Baseline (Student Only):</strong> {baseline_acc:.1f}%</p>\n",
    "            <p style='margin: 5px 0;'><strong>ATLAS (Student+Teacher):</strong> {atlas_acc:.1f}%</p>\n",
    "            <p style='margin: 5px 0; color: #228B22;'><strong>Improvement:</strong> +{improvement:.1f}%</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h4 style='margin: 0; color: #4169E1;'>üõ°Ô∏è Reliability</h4>\n",
    "            <p style='margin: 5px 0;'><strong>Problems Improved:</strong> {metrics['improvements']}</p>\n",
    "            <p style='margin: 5px 0;'><strong>Problems Degraded:</strong> {metrics['degradations']}</p>\n",
    "            <p style='margin: 5px 0; color: #228B22;'><strong>Non-Degradation Rate:</strong> {ndr:.1f}%</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div style='margin-top: 15px; padding: 10px; background-color: white; border-radius: 5px;'>\n",
    "        <h4 style='margin: 0 0 10px 0; color: #FF6347;'>üöÄ Why This Matters</h4>\n",
    "        <ul style='margin: 0; padding-left: 20px;'>\n",
    "            <li><strong>Model-Agnostic:</strong> Works with any student model (Qwen, Llama, etc.)</li>\n",
    "            <li><strong>Adaptive:</strong> Teaching strategy adjusts based on problem difficulty</li>\n",
    "            <li><strong>Reliable:</strong> {ndr:.1f}% of responses maintained or improved quality</li>\n",
    "            <li><strong>Efficient:</strong> Minimal teacher guidance achieves significant gains</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(summary_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Extending This Demo\n",
    "\n",
    "### Use Your Own Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "extension-example"
   },
   "outputs": [],
   "source": [
    "# Example: How to use a different student model\n",
    "print(\"üí° To use your own student model:\")\n",
    "print(\"\\n1. Replace the model name:\")\n",
    "print('   student_model_name=\"your/model-name\"')\n",
    "print(\"\\n2. Keep the same ATLAS teacher:\")\n",
    "print('   teacher_thinking_name=\"Arc-Intelligence/ATLAS-8B-Thinking\"')\n",
    "print(\"\\n3. Run the same evaluation pipeline!\")\n",
    "\n",
    "print(\"\\nüéØ Supported Student Models:\")\n",
    "supported_models = [\n",
    "    \"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\", \n",
    "    \"microsoft/DialoGPT-medium\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    \"Any HuggingFace compatible model!\"\n",
    "]\n",
    "\n",
    "for model in supported_models:\n",
    "    print(f\"   ‚úÖ {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Problem Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom-problems"
   },
   "outputs": [],
   "source": [
    "# Example: Add your own math problems\n",
    "custom_problems = [\n",
    "    {\n",
    "        \"problem\": \"A company's profit increased from $50,000 to $65,000. What was the percentage increase?\",\n",
    "        \"answer\": 30,\n",
    "        \"solution\": \"Increase = $65,000 - $50,000 = $15,000. Percentage = ($15,000 / $50,000) √ó 100% = 30%\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"If 3^x = 27, what is the value of x?\", \n",
    "        \"answer\": 3,\n",
    "        \"solution\": \"3^x = 27 = 3^3, therefore x = 3\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üîß Custom Problems Example:\")\n",
    "for i, prob in enumerate(custom_problems):\n",
    "    print(f\"\\n{i+1}. {prob['problem']}\")\n",
    "    print(f\"   Expected: {prob['answer']}\")\n",
    "\n",
    "print(\"\\nüí° To use custom problems:\")\n",
    "print(\"   problems = custom_problems\")\n",
    "print(\"   # Then run the same evaluation pipeline!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Try the Code Generation Demo**: [`code_generation_demo.ipynb`](code_generation_demo.ipynb)\n",
    "2. **Train Your Own Teacher**: See the main [ATLAS repository](https://github.com/Arc-Intelligence/RCL)\n",
    "3. **Production Deployment**: Check our [documentation](../README.md)\n",
    "4. **Join the Community**: [GitHub Issues](https://github.com/Arc-Intelligence/RCL/issues)\n",
    "\n",
    "---\n",
    "\n",
    "**Citation:**\n",
    "```bibtex\n",
    "@article{atlas2025,\n",
    "  title     = {ATLAS: Adaptive Training Methodology for RL},\n",
    "  author    = {Arc Intelligence},\n",
    "  journal   = {arXiv preprint},\n",
    "  year      = {2025}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}