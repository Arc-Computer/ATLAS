{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atlas-code-demo-header"
   },
   "source": [
    "# ATLAS Code Generation Demo\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Arc-Intelligence/RCL/blob/main/examples/code_generation_demo.ipynb)\n",
    "\n",
    "## üéØ Goal: Better Code Quality & Explanations in < 7 Minutes\n",
    "\n",
    "This notebook demonstrates ATLAS improving code generation through adaptive teaching:\n",
    "1. **Diagnostic Probing**: Teacher assesses coding capability\n",
    "2. **Adaptive Teaching**: Provides hints vs full solutions based on assessment\n",
    "\n",
    "**Models Used:**\n",
    "- **Student**: Qwen/Qwen3-4B-Instruct-2507\n",
    "- **Teacher**: ATLAS-8B-Instruct\n",
    "- **Dataset**: HumanEval coding problems\n",
    "\n",
    "**Hardware Requirements:** Single GPU (T4/A100), 12-16GB RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-environment"
   },
   "outputs": [],
   "source": [
    "# Install dependencies (Colab)\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q transformers datasets torch accelerate\n",
    "    !pip install -q matplotlib seaborn pandas numpy\n",
    "    \n",
    "    # Clone repository for utils\n",
    "    !git clone -q https://github.com/Arc-Intelligence/RCL.git\n",
    "    sys.path.append('/content/RCL/examples')\n",
    "else:\n",
    "    # Local development\n",
    "    sys.path.append('.')\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, Code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import ATLAS utilities\n",
    "from utils.atlas_inference import ATLASInference, load_atlas_models\n",
    "from utils.evaluation import calculate_metrics\n",
    "from utils.visualization import plot_comparison, display_results_table, show_example_comparisons\n",
    "from data.load_datasets import load_code_problems\n",
    "\n",
    "print(\"üìö Libraries imported successfully\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Load Coding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-dataset"
   },
   "outputs": [],
   "source": [
    "# Load coding problems from HuggingFace\n",
    "print(\"Loading coding problems from HuggingFace...\\n\")\n",
    "\n",
    "try:\n",
    "    problems = load_code_problems(num_samples=15)\n",
    "    print(f\"‚úÖ Loaded {len(problems)} coding problems\")\nexcept Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  HumanEval dataset failed: {e}\")\n",
    "    print(\"Using fallback sample problems...\")\n",
    "    from data.load_datasets import get_sample_code_problems\n",
    "    problems = get_sample_code_problems()\n",
    "\n",
    "print(f\"\\nüìù Dataset Summary:\")\n",
    "print(f\"   Total problems: {len(problems)}\")\n",
    "print(f\"   Source: {problems[0].get('source', 'unknown')}\")\n",
    "\n",
    "# Show sample problem\n",
    "sample = problems[0]\n",
    "print(f\"\\nüîç Sample Coding Problem:\")\n",
    "print(f\"Task: {sample['problem'][:200]}{'...' if len(sample['problem']) > 200 else ''}\")\n",
    "print(f\"Expected: {sample.get('expected_behavior', 'N/A')[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Load Models\n",
    "\n",
    "Loading the student model (Qwen3-4B-Instruct-2507) and ATLAS teacher (ATLAS-8B-Instruct) for code tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-models"
   },
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading ATLAS models for code generation...\\n\")\n",
    "\n",
    "# Load models with memory optimization\n",
    "device_map = \"auto\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "try:\n",
    "    _, code_atlas = load_atlas_models(\n",
    "        student_model_name=\"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "        teacher_instruct_name=\"Arc-Intelligence/ATLAS-8B-Instruct\",\n",
    "        device_map=device_map,\n",
    "        torch_dtype=torch_dtype\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Models loaded successfully!\")\n",
    "    \n",
    "    # Memory check\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.memory_allocated() / 1024**3\n",
    "        memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"üìä GPU Memory: {memory_used:.1f}GB / {memory_total:.1f}GB ({memory_used/memory_total*100:.1f}%)\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"‚ùå Error loading models: {e}\")\n",
    "    print(\"This demo requires GPU access. Please ensure you have:\")\n",
    "    print(\"- GPU runtime enabled in Colab\")\n",
    "    print(\"- Sufficient GPU memory (12GB+ recommended)\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† ATLAS Code Teaching in Action\n",
    "\n",
    "Let's see how ATLAS adapts its teaching for a coding problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo-single-example"
   },
   "outputs": [],
   "source": [
    "# Demo with single coding problem\n",
    "demo_problem = problems[0]\n",
    "print(f\"üéØ Demo Coding Task:\")\n",
    "print(f\"{demo_problem['problem']}\\n\")\n",
    "\n",
    "print(\"üîç Phase 1: Diagnostic Probing\")\n",
    "diagnostic_result = code_atlas.diagnostic_probe(demo_problem['problem'])\n",
    "print(f\"Coding Capability Score: {diagnostic_result['capability_score']}/5\")\n",
    "print(f\"Teaching Strategy: {diagnostic_result['teaching_strategy']}\")\n",
    "print(f\"Assessment: {diagnostic_result['probe_response'][:200]}...\\n\")\n",
    "\n",
    "print(\"üéì Phase 2: Adaptive Teaching\")\n",
    "teaching_result = code_atlas.adaptive_teaching(demo_problem['problem'], diagnostic_result)\n",
    "print(f\"Teaching Guidance: {teaching_result['teaching_guidance'][:300]}...\\n\")\n",
    "\n",
    "print(\"üë§ Student Baseline Code:\")\n",
    "baseline_response = code_atlas.generate_student_response(demo_problem['problem'])\n",
    "print(f\"{baseline_response[:400]}...\\n\")\n",
    "\n",
    "print(\"‚ú® Student + Teacher Code:\")\n",
    "guided_response = code_atlas.generate_student_response(\n",
    "    demo_problem['problem'], \n",
    "    teaching_result['teaching_guidance']\n",
    ")\n",
    "print(f\"{guided_response[:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Full Code Generation Evaluation\n",
    "\n",
    "Running the complete evaluation across all coding problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "full-evaluation"
   },
   "outputs": [],
   "source": [
    "print(f\"üöÄ Running full evaluation on {len(problems)} coding problems...\\n\")\n",
    "\n",
    "# Run ATLAS protocol on all coding problems\n",
    "results = []\n",
    "for i, problem in enumerate(problems):\n",
    "    print(f\"Processing problem {i+1}/{len(problems)}...\", end=\"\\r\")\n",
    "    \n",
    "    try:\n",
    "        result = code_atlas.run_full_protocol(problem['problem'])\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Error on problem {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation complete! Processed {len(results)} problems successfully.\")\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "print(\"\\nüìà Calculating code quality metrics...\")\n",
    "metrics = calculate_metrics(problems[:len(results)], results, task_type=\"code\")\n",
    "\n",
    "print(f\"\\nüéØ Key Results:\")\n",
    "print(f\"   Baseline Quality Score: {metrics['avg_baseline_score']:.1%}\")\n",
    "print(f\"   ATLAS Quality Score: {metrics['avg_guided_score']:.1%}\")\n",
    "print(f\"   Quality Improvement: +{metrics['improvement_percentage']:.1f}%\")\n",
    "print(f\"   Problems Improved: {metrics['improvements']}\")\n",
    "print(f\"   Problems Degraded: {metrics['degradations']}\")\n",
    "print(f\"   Non-Degradation Rate: {metrics['non_degradation_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Code Quality Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-results"
   },
   "outputs": [],
   "source": [
    "# Create comprehensive performance plots\n",
    "plot_comparison(metrics, task_type=\"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-table"
   },
   "outputs": [],
   "source": [
    "# Display detailed results table\n",
    "display_results_table(metrics, task_type=\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Code Example Comparisons\n",
    "\n",
    "Side-by-side comparison of generated code quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "code-comparisons"
   },
   "outputs": [],
   "source": [
    "# Show detailed code comparisons\n",
    "def show_code_comparisons(problems, results, num_examples=3):\n",
    "    \"\"\"\n",
    "    Show side-by-side code comparisons with syntax highlighting.\n",
    "    \"\"\"\n",
    "    display(HTML(\"<h3>üìù Code Generation Comparisons: Student vs Student+Teacher</h3>\"))\n",
    "    \n",
    "    for i in range(min(num_examples, len(results))):\n",
    "        problem = problems[i]\n",
    "        result = results[i]\n",
    "        \n",
    "        # Extract code from responses\n",
    "        baseline_code = result['baseline_response']\n",
    "        guided_code = result['guided_response']\n",
    "        \n",
    "        comparison_html = f\"\"\"\n",
    "        <div style='margin-bottom: 30px; border: 1px solid #ddd; padding: 15px; border-radius: 8px;'>\n",
    "            <h4>Example {i+1}: Coding Task</h4>\n",
    "            \n",
    "            <div style='background-color: #fff3cd; padding: 10px; border-radius: 5px; margin-bottom: 15px;'>\n",
    "                <h5 style='color: #856404; margin-top: 0;'>üìã Task Description</h5>\n",
    "                <p style='margin: 0; font-size: 14px; font-family: monospace;'>{problem.get('problem', 'N/A')}</p>\n",
    "            </div>\n",
    "            \n",
    "            <div style='background-color: #e8f4f8; padding: 10px; border-radius: 5px; margin-bottom: 15px;'>\n",
    "                <h5 style='color: #0c5460; margin-top: 0;'>üéØ Teaching Strategy: {result['teaching']['strategy'].title()}</h5>\n",
    "                <p style='margin: 0; font-size: 12px;'>{result['teaching']['teaching_guidance'][:200]}...</p>\n",
    "            </div>\n",
    "            \n",
    "            <div style='display: flex; gap: 20px;'>\n",
    "                <div style='flex: 1;'>\n",
    "                    <h5 style='color: #721c24; background-color: #f8d7da; padding: 8px; border-radius: 5px; margin: 0;'>üë§ Student Alone</h5>\n",
    "                    <pre style='background-color: #f8f9fa; padding: 10px; border-radius: 5px; overflow-x: auto; font-size: 12px;'><code>{baseline_code[:500]}{'...' if len(baseline_code) > 500 else ''}</code></pre>\n",
    "                </div>\n",
    "                \n",
    "                <div style='flex: 1;'>\n",
    "                    <h5 style='color: #155724; background-color: #d4edda; padding: 8px; border-radius: 5px; margin: 0;'>‚ú® Student + Teacher</h5>\n",
    "                    <pre style='background-color: #f8f9fa; padding: 10px; border-radius: 5px; overflow-x: auto; font-size: 12px;'><code>{guided_code[:500]}{'...' if len(guided_code) > 500 else ''}</code></pre>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        display(HTML(comparison_html))\n",
    "\n",
    "# Show code comparisons\n",
    "show_code_comparisons(problems[:len(results)], results, num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Teaching Strategy Analysis\n",
    "\n",
    "Understanding how ATLAS adapts for different coding complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diagnostic-analysis"
   },
   "outputs": [],
   "source": [
    "from utils.visualization import create_diagnostic_analysis\n",
    "\n",
    "# Analyze diagnostic probing results for coding tasks\n",
    "create_diagnostic_analysis(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Code Quality Breakdown\n",
    "\n",
    "Detailed analysis of what makes the code better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quality-analysis"
   },
   "outputs": [],
   "source": [
    "# Analyze specific code quality improvements\n",
    "from utils.evaluation import check_code_correctness\n",
    "\n",
    "quality_analysis = {\n",
    "    'has_function': {'baseline': 0, 'guided': 0},\n",
    "    'has_return': {'baseline': 0, 'guided': 0},\n",
    "    'has_documentation': {'baseline': 0, 'guided': 0},\n",
    "    'estimated_correctness': {'baseline': 0, 'guided': 0}\n",
    "}\n",
    "\n",
    "for result in results:\n",
    "    baseline_eval = check_code_correctness(result['baseline_response'], \"\")\n",
    "    guided_eval = check_code_correctness(result['guided_response'], \"\")\n",
    "    \n",
    "    for metric in quality_analysis:\n",
    "        if baseline_eval.get(metric, False):\n",
    "            quality_analysis[metric]['baseline'] += 1\n",
    "        if guided_eval.get(metric, False):\n",
    "            quality_analysis[metric]['guided'] += 1\n",
    "\n",
    "# Create quality comparison chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "metrics_labels = ['Function Definition', 'Return Statement', 'Documentation', 'Estimated Correctness']\n",
    "baseline_counts = [quality_analysis[k]['baseline'] for k in ['has_function', 'has_return', 'has_documentation', 'estimated_correctness']]\n",
    "guided_counts = [quality_analysis[k]['guided'] for k in ['has_function', 'has_return', 'has_documentation', 'estimated_correctness']]\n",
    "\n",
    "x = np.arange(len(metrics_labels))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, baseline_counts, width, label='Student Alone', color='#ff7f0e', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, guided_counts, width, label='Student + Teacher', color='#2ca02c', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Code Quality Metrics')\n",
    "ax.set_ylabel('Number of Solutions')\n",
    "ax.set_title('Code Quality Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_labels)\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nüìä Code Quality Improvements:\")\n",
    "for i, (metric_key, metric_label) in enumerate(zip(['has_function', 'has_return', 'has_documentation', 'estimated_correctness'], metrics_labels)):\n",
    "    baseline_pct = quality_analysis[metric_key]['baseline'] / len(results) * 100\n",
    "    guided_pct = quality_analysis[metric_key]['guided'] / len(results) * 100\n",
    "    improvement = guided_pct - baseline_pct\n",
    "    print(f\"   {metric_label}: {baseline_pct:.0f}% ‚Üí {guided_pct:.0f}% (+{improvement:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways for Developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "developer-insights"
   },
   "outputs": [],
   "source": [
    "# Generate developer-focused insights\n",
    "baseline_score = metrics['avg_baseline_score'] * 100\n",
    "atlas_score = metrics['avg_guided_score'] * 100\n",
    "improvement = metrics['improvement_percentage']\n",
    "ndr = metrics['non_degradation_rate'] * 100\n",
    "\n",
    "developer_html = f\"\"\"\n",
    "<div style='background-color: #f0f8ff; padding: 20px; border-radius: 10px; border-left: 5px solid #4CAF50;'>\n",
    "    <h3 style='color: #2E8B57; margin-top: 0;'>üíª ATLAS Code Generation Results</h3>\n",
    "    \n",
    "    <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 15px 0;'>\n",
    "        <div>\n",
    "            <h4 style='margin: 0; color: #4169E1;'>üìä Quality Scores</h4>\n",
    "            <p style='margin: 5px 0;'><strong>Baseline (Student Only):</strong> {baseline_score:.1f}%</p>\n",
    "            <p style='margin: 5px 0;'><strong>ATLAS (Student+Teacher):</strong> {atlas_score:.1f}%</p>\n",
    "            <p style='margin: 5px 0; color: #228B22;'><strong>Improvement:</strong> +{improvement:.1f}%</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h4 style='margin: 0; color: #4169E1;'>üõ°Ô∏è Reliability</h4>\n",
    "            <p style='margin: 5px 0;'><strong>Problems Improved:</strong> {metrics['improvements']}</p>\n",
    "            <p style='margin: 5px 0;'><strong>Problems Degraded:</strong> {metrics['degradations']}</p>\n",
    "            <p style='margin: 5px 0; color: #228B22;'><strong>Non-Degradation Rate:</strong> {ndr:.1f}%</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div style='margin-top: 15px; padding: 10px; background-color: white; border-radius: 5px;'>\n",
    "        <h4 style='margin: 0 0 10px 0; color: #FF6347;'>üöÄ Developer Benefits</h4>\n",
    "        <ul style='margin: 0; padding-left: 20px;'>\n",
    "            <li><strong>Better Code Structure:</strong> More functions, return statements, and documentation</li>\n",
    "            <li><strong>Adaptive Guidance:</strong> Hints for simple tasks, full examples for complex ones</li>\n",
    "            <li><strong>Language Agnostic:</strong> Works with Python, JavaScript, Java, C++, etc.</li>\n",
    "            <li><strong>IDE Integration Ready:</strong> Can be integrated into development workflows</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \n",
    "    <div style='margin-top: 15px; padding: 10px; background-color: #e8f4f8; border-radius: 5px;'>\n",
    "        <h4 style='margin: 0 0 10px 0; color: #0c5460;'>üí° Use Cases</h4>\n",
    "        <ul style='margin: 0; padding-left: 20px;'>\n",
    "            <li>Code completion and generation</li>\n",
    "            <li>Code review and improvement suggestions</li>\n",
    "            <li>Educational coding assistance</li>\n",
    "            <li>Technical interview preparation</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(developer_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Extending This Demo\n",
    "\n",
    "### Custom Coding Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom-tasks"
   },
   "outputs": [],
   "source": [
    "# Example: Add your own coding challenges\n",
    "custom_coding_problems = [\n",
    "    {\n",
    "        \"problem\": \"Write a function that finds the longest common subsequence between two strings.\",\n",
    "        \"expected_behavior\": \"lcs('ABCDGH', 'AEDFHR') should return 'ADH' or similar LCS\",\n",
    "        \"canonical_solution\": \"def lcs(s1, s2):\\n    # Dynamic programming solution\\n    m, n = len(s1), len(s2)\\n    dp = [[0]*(n+1) for _ in range(m+1)]\\n    # ... implementation\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Create a class that implements a basic LRU (Least Recently Used) cache.\",\n",
    "        \"expected_behavior\": \"LRU cache with get/put operations and capacity limit\",\n",
    "        \"canonical_solution\": \"class LRUCache:\\n    def __init__(self, capacity):\\n        # Implementation using OrderedDict or doubly linked list\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üõ†Ô∏è  Custom Coding Challenges:\")\n",
    "for i, prob in enumerate(custom_coding_problems):\n",
    "    print(f\"\\n{i+1}. {prob['problem']}\")\n",
    "    print(f\"   Expected: {prob['expected_behavior']}\")\n",
    "\n",
    "print(\"\\nüí° To use custom problems:\")\n",
    "print(\"   problems = custom_coding_problems\")\n",
    "print(\"   # Then run the same evaluation pipeline!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Programming Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "multi-language"
   },
   "outputs": [],
   "source": [
    "# Example: Test with different programming languages\n",
    "multilang_problems = [\n",
    "    {\n",
    "        \"problem\": \"Write a JavaScript function that debounces another function call.\",\n",
    "        \"language\": \"javascript\",\n",
    "        \"expected_behavior\": \"Delays function execution until after delay milliseconds have passed\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Implement a generic binary search tree in Java with insert and find operations.\",\n",
    "        \"language\": \"java\",\n",
    "        \"expected_behavior\": \"BST class with generic type support and standard operations\"\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Write a C++ function that performs matrix multiplication efficiently.\",\n",
    "        \"language\": \"cpp\",\n",
    "        \"expected_behavior\": \"Multiply two matrices with proper dimension checking\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üåç Multi-Language Support:\")\n",
    "for prob in multilang_problems:\n",
    "    print(f\"\\n‚Ä¢ {prob['language'].upper()}: {prob['problem'][:60]}...\")\n",
    "\n",
    "print(\"\\n‚ú® ATLAS adapts its teaching style for different programming languages and paradigms!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Try the Math Reasoning Demo**: [`math_reasoning_demo.ipynb`](math_reasoning_demo.ipynb)\n",
    "2. **Integrate with Your IDE**: Use ATLAS for real development workflows\n",
    "3. **Train Custom Teachers**: Specialize for your domain/language\n",
    "4. **Production Deployment**: Scale to serve your development team\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- **Main Repository**: [ATLAS Training Pipeline](https://github.com/Arc-Intelligence/RCL)\n",
    "- **Documentation**: [Setup & Configuration](../README.md)\n",
    "- **Models**: [ATLAS-8B-Instruct](https://huggingface.co/Arc-Intelligence/ATLAS-8B-Instruct)\n",
    "- **Community**: [GitHub Discussions](https://github.com/Arc-Intelligence/RCL/discussions)\n",
    "\n",
    "---\n",
    "\n",
    "**Citation:**\n",
    "```bibtex\n",
    "@article{atlas2025,\n",
    "  title     = {ATLAS: Adaptive Training Methodology for RL},\n",
    "  author    = {Arc Intelligence},\n",
    "  journal   = {arXiv preprint},\n",
    "  year      = {2025}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",\n",
  "colab": {
   "gpuType": "T4",\n",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}