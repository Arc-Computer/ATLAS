---
title: Teacher-Student Paradigm
description: The foundational concept enabling adaptive performance enhancement
sidebarTitle: Teacher-Student Concept
icon: chalkboard-user
---

The teacher-student paradigm is the core idea behind ATLAS: a specialized teacher model enhances any student model's performance without modifying the student's weights.

Think of it like hiring an expert tutor for your existing team. The tutor (teacher) doesn't replace your team members (student models)—instead, it helps them perform better on specific tasks through real-time guidance.

## Core Concept

**Student**: Any LLM you want to enhance (GPT, Claude, Llama, your custom model, etc.)

**Teacher**: A specialized 8B model trained to provide adaptive guidance

**Result**: Student produces better outputs without any retraining

### Key Advantage: Model Agnostic

Unlike fine-tuning or RLHF, which require modifying model weights, ATLAS works with any model through inference-time guidance:

| Traditional Approach | ATLAS Approach |
|---------------------|----------------|
| Retrain the student model | Keep student model frozen |
| Requires model access and compute | Works with API-only models |
| Risk of capability loss | Preserves all original capabilities |
| Weeks to deploy changes | Hours to deploy improvements |

## Runtime vs Training Context

<Note>
**Two ways to meet the Student and Teacher:** the SDK runtime uses them to execute a single task, while the training system uses them to *improve* future teachers.
</Note>

| Context | Where you see it | Student role | Teacher role | Goal |
|---------|------------------|--------------|--------------|------|
| **SDK Runtime** | [`sdk/quickstart`](/sdk/quickstart), [`How Orchestration Works`](/sdk/orchestration) | Plans, executes, and synthesizes answers using your adapter | Reviews plans, validates steps, and requests retries | Produce a high-quality answer right now |
| **Training & Optimization** | [`Quickstart`](/quickstart), [`First Experiment`](/first-experiment) | The model being improved (e.g., teacher checkpoint) | The supervising coach generating training signals | Improve long-term model behavior |

When writing or reading docs, look for the “Switching between Runtime and Training?” callout for navigation help. The in-depth runtime roles live at [`Student & Teacher Roles`](/sdk/student-teacher-roles).

## Why This Works

### 1. Asymmetric Specialization

The teacher model is smaller (8B parameters) but specialized for one job: generating helpful teaching. The student model can be any size and handles the actual task.

**Analogy**: A coding interview coach (teacher) doesn't need to be a better programmer than you (student). They just need to be excellent at identifying gaps in your approach and providing targeted feedback.

### 2. Inference-Time Enhancement

Teaching happens through prompting at inference time:
1. Teacher analyzes the task and student capability
2. Teacher generates guidance as text
3. Guidance is added to student's prompt
4. Student generates improved response

No gradient updates, no fine-tuning, no model modification required.

### 3. Adaptive Intensity

The teacher adjusts guidance based on student capability:
- **Strong student**: Minimal intervention (50-100 tokens)
- **Weak student**: Comprehensive help (200-300 tokens)

This saves both cost and context length while ensuring safety.

## Model Requirements

| Component | Specification | Purpose |
|-----------|--------------|---------|
| Teacher Model | 8B parameters, RL-trained | Generates adaptive guidance |
| Student Model | Any size (4B-70B+), any provider | Executes enhanced reasoning |
| Context Window | 4096-32768 tokens | Accommodates teaching interaction |
| Inference Overhead | +30% latency | Two-pass protocol cost |

## Performance on τ²-bench

State-of-the-art results on complex multi-step tasks (mms_issue subset):

| System | Pass@1 Rate | Notes |
|--------|-------------|-------|
| **ATLAS Teacher-Student** | **24.0%** | Minimal degradation across attempts |
| GPT-4.1 | 18.0% | -8pt drop from Pass@1 to Pass@4 |
| Claude 3.7 Sonnet | 18.0% | -16pt drop from Pass@1 to Pass@4 |
| o4-mini | 12.0% | -10pt drop from Pass@1 to Pass@4 |
| Qwen3-8B (Student Only) | 4.1% | No teacher guidance |

**Key observations:**
- **6x performance lift**: Teacher guidance improves Qwen3-8B from 4.1% to 24.0%
- **Consistency advantage**: ATLAS shows minimal degradation across multiple attempts
- **Cross-domain transfer**: Math-trained teacher successfully guides telecom debugging tasks

### Aggregate Metrics
- **Average accuracy improvement (runtime + GRPO)**: 15.7% across all benchmarks
- **Online optimization lift (GEPA)**: Up to +165% in ~2 hours for domain-specific tasks
- **Maximum observed improvement**: 29.6% on specific domains (closed-loop baseline)
- **Non-degradation rate**: 97% (safe to deploy)
- **Token efficiency**: 50% reduction (4k → 2k tokens)
- **Completion rate**: 31% improvement (69% → 100%)

## Advantages Over Alternatives

### vs. Fine-tuning
- **No retraining required**: Works with frozen student models
- **Preserves capabilities**: No catastrophic forgetting
- **Instant deployment**: No training time or compute cost

### vs. Prompt Engineering
- **Adaptive**: Adjusts to student capability automatically
- **Consistent**: Systematic improvement, not trial-and-error
- **Efficient**: Optimized token usage based on need

### vs. Ensemble Methods
- **Lower latency**: Single student inference (not multiple models)
- **Lower cost**: No redundant model calls
- **Better interpretability**: Clear teaching rationale

## How It's Trained

The teacher model undergoes two-phase training:

**Phase 1: Supervised Fine-Tuning (SFT)**
- Learns basic teaching patterns
- Establishes foundational reasoning
- ~4-6 hours on 8× H100 GPUs

**Phase 2: Reinforcement Learning (GRPO)**
- Optimizes for student performance improvement
- Learns adaptive capability assessment
- ~24-36 hours on 8× H100 GPUs

The reward signal comes from measuring actual student improvement, creating a teacher that's incentivized to make students succeed.

## Integration Patterns

### Pattern 1: Direct Enhancement

```python
from trainers.prompt_adapter import ATLASGEPAAdapter

adapter = ATLASGEPAAdapter(
    teacher_model=teacher_generate_fn,
    student_model=student_generate_fn,
    all_prompts=optimized_prompts
)

result = adapter.evaluate([{"question": user_query}])
enhanced_output = result.outputs[0]["student_with_teaching"]
```

### Pattern 2: Batch Processing

```python
# Efficient processing of multiple queries
queries = [{"question": q} for q in query_list]
results = adapter.evaluate(queries, capture_traces=True)
enhanced_outputs = [r["student_with_teaching"] for r in results.outputs]
```

## Best Practices

<AccordionGroup>
  <Accordion title="Teacher Model Selection">
    Choose based on task type:
    - **ATLAS-8B-Thinking**: Mathematical and logical reasoning
    - **ATLAS-8B-Instruct**: Code generation and technical tasks
    - **Custom trained**: Domain-specific requirements
  </Accordion>

  <Accordion title="Student Model Compatibility">
    Verify student model supports:
    - System prompts or instruction following
    - Sufficient context length (>4K tokens)
    - Deterministic generation (temperature control)
  </Accordion>

  <Accordion title="Performance Optimization">
    - Cache teacher guidance for repeated queries
    - Batch similar tasks together
    - Use streaming for interactive applications
    - Monitor token usage for cost control
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols="2">
  <Card title="How ATLAS Works" icon="arrows-rotate" href="/concepts/adaptive-teaching-protocol">
    Detailed two-pass protocol and implementation
  </Card>
  <Card title="Deploy to Production" icon="plug" href="/integration/inference-only">
    Integrate teacher-student system into your pipeline
  </Card>
  <Card title="Reward System" icon="trophy" href="/concepts/reward-design">
    How teaching effectiveness is measured
  </Card>
  <Card title="Performance Benchmarks" icon="chart-line" href="/examples/sota-on-tau-squared-bench">
    Detailed τ²-bench results and analysis
  </Card>
</CardGroup>

## References

- [ATLAS Technical Report](/reference/technical-report) - Complete methodology and architecture
- [First Experiment](/first-experiment) - Hands-on teacher training walkthrough
- [Online Optimization Demo](/examples/online_optimization) - Interactive teaching optimization
