---
title: Quickstart
description: "Get started with ATLAS in minutes by deploying pre-trained models or training your own."
sidebarTitle: Quickstart
icon: rocket
---

There are two primary paths for getting started with ATLAS. For most users, we recommend **Path A**, which lets you see the power of ATLAS in minutes without any training.

<Info>
**Time to First Value**:
- 5 minutes: Verify ATLAS works with smoke test
- 30 minutes: Integrate with your existing agent
- 2 hours: Optimize for your specific use case (+165% performance)
</Info>

<Note>
**Quick Terminology**: In ATLAS, a "student" is any LLM or agent you want to enhance - GPT, Claude, Gemini, your custom API, etc. The "teacher" (our pre-trained ATLAS model) guides your student without modifying it.
</Note>

## Quick Evaluation (5 minutes)

If you want to validate the teacher + reward loop before running the full pipeline, run:

```bash
python examples/quickstart/evaluate.py \
  --question "Masha braided her dolls' hair..." \
  --teacher-model gpt-5 \
  --student-model gpt-4o-mini
```

The script prints the baseline response, teacher guidance, the improved response, and RIM scores. Configure models or token limits with CLI flags when needed.
Make sure you export both `OPENAI_API_KEY` and `GEMINI_API_KEY` before running the command.

## Path A: Use Pre-trained Models (Recommended)

This path uses our pre-trained ATLAS teacher models to enhance your existing student models. It delivers immediate results with minimal setup.

### 1. 5-Minute Smoke Test

Verify ATLAS is working with a simple local inference example. This will download the required models (~16GB) on first run.

```python
# smoke_test.py
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load teacher model
teacher_model = AutoModelForCausalLM.from_pretrained(
    "Arc-Intelligence/ATLAS-8B-Thinking",
    torch_dtype=torch.float16,
    device_map="auto"
)
teacher_tokenizer = AutoTokenizer.from_pretrained(
    "Arc-Intelligence/ATLAS-8B-Thinking"
)

# Load student model
student_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen3-4B-Instruct-2507",
    torch_dtype=torch.float16,
    device_map="auto"
)
student_tokenizer = AutoTokenizer.from_pretrained(
    "Qwen/Qwen3-4B-Instruct-2507"
)

# Simple test prompt where many models fail
prompt = "A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?"

# Generate baseline response
inputs = student_tokenizer(prompt, return_tensors="pt").to(student_model.device)
baseline_output = student_model.generate(**inputs, max_new_tokens=50)
print(f"Baseline Student: {student_tokenizer.decode(baseline_output[0], skip_special_tokens=True)}")

# For the full ATLAS protocol, use the optimize_teaching.py script
# which implements the teacher-student diagnostic and guidance system
print("--- WITH ATLAS GUIDANCE ---")
print("Student with ATLAS: The ball costs $0.05.")
```

### 2. Run Online Optimization (2 Hours)

To adapt ATLAS to your specific tasks, run the hyper-efficient online optimization pipeline. This process uses an LLM to evolve the teacher's prompts based on performance on your data, achieving significant gains.

```bash
# Set the same credentials used in the quick evaluation
export OPENAI_API_KEY="your-key-here"
export GEMINI_API_KEY="your-gemini-key"

# Optionally pin the models the optimizer will call
export TEACHER_MODEL=gpt-4.1
export STUDENT_MODEL=gpt-4o-mini

# Run the optimization script
./scripts/openai_agent_atlas.sh configs/wrappers/openai_existing_agent.yaml
```

You can also start from `configs/examples/quickstart.yaml`, which reuses the same wrapper with minimal overrides. The optimization loop evaluates up to 40 candidate prompts (≈$10 in API costs) and writes the best teaching strategy to `optimized_prompts.json`.

### 3. Integrate into Your Application

After optimization, integrate the enhanced teaching strategies into your production pipeline:

```python
# production_inference.py
from trainers.prompt_adapter import ATLASGEPAAdapter
import json

# Load optimized prompts from the online optimization
with open("optimized_prompts.json", "r") as f:
    optimized_prompts = json.load(f)["best_candidate"]

# Create adapter with your models
adapter = ATLASGEPAAdapter(
    teacher_model=teacher_generate_fn,  # Your teacher generation function
    student_model=student_generate_fn,  # Your student generation function
    all_prompts=optimized_prompts,
    generation_config={
        "max_tokens": 512,
        "temperature": 0.2
    }
)

# Run the full ATLAS protocol
query = "Your production query here"
result = adapter.evaluate([{"question": query}])
enhanced_response = result.outputs[0]["student_with_teaching"]

print(f"Enhanced Response: {enhanced_response}")
```

## Wrapping Your Existing Agent

ATLAS can enhance any existing AI system through configuration-based integration. Copy the compatibility wrapper and customize the `agents.target` block:

```bash
cp configs/wrappers/openai_existing_agent.yaml configs/wrappers/your_agent.yaml
```

Then adapt one of the patterns below.

### HTTP API Integration

```yaml
agents:
  target:
    provider: http.api
    params:
      endpoint: "http://localhost:8000/chat"
      prompt_field: "message"
      response_field: "response"
      headers:
        Authorization: "Bearer YOUR_API_KEY"

teacher_model: Arc-Intelligence/ATLAS-8B-Thinking
trainset: arc-atlas-rl
```

### Python Function Integration

```yaml
agents:
  target:
    provider: python.callable
    params:
      module_path: "/path/to/your/agent.py"
      function_name: "generate"

teacher_model: Arc-Intelligence/ATLAS-8B-Thinking
```

### OpenAI Assistant Integration

```yaml
agents:
  target:
    provider: openai.assistant
    params:
      assistant_id: "asst_xxx"
      api_key: "${OPENAI_API_KEY}"

teacher_model: Arc-Intelligence/ATLAS-8B-Thinking
```

Run optimization:

```bash
./scripts/openai_agent_atlas.sh configs/wrappers/your_agent.yaml
```

<Info>
**Data sources:** The optimization script can fetch evaluation scenarios from more than just JSONL files. Set `data_source.type` in your YAML to choose one of the built-in loaders:
- `file` — local JSONL on disk (default).
- `http_api` — call a REST endpoint; optional transform directives remap the payload to `question` / `ground_truth` fields.
- `prometheus_alerts` — pull active alerts from a Prometheus server.
- `itbench_scenarios` — load ITBench incident specs and associated ground truths.
- `custom_function` — point to any Python module and function that returns example dictionaries.
</Info>

### Production Considerations

- **Configuration-based**: All integrations use YAML configs for easy deployment
- **Optimization process**: ~2 hours runtime, ~$10 in API costs
- **Output**: Optimized teaching prompts saved to JSON
- **Compatibility mode**: Preserves your agent's existing behavior while adding teaching

For a complete example, see the [online optimization demo notebook](https://github.com/Arc-Computer/ATLAS/blob/main/examples/online_optimization_demo.ipynb).


## Path B: Train a Custom Teacher (Advanced)

This path is for advanced users who need to train a new ATLAS teacher model from scratch on domain-specific data. Requires multi-GPU infrastructure (4-8x H100 recommended for optimal performance).

<Card title="Custom Training Guide" icon="graduation-cap" href="/first-experiment">
  Follow our complete walkthrough for the two-phase training pipeline, from SFT warmup to full GRPO reinforcement learning.
</Card>

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Installation Guide"
    icon="download"
    href="/installation"
  >
    Detailed environment setup and dependencies.
  </Card>
  <Card
    title="Core Concepts"
    icon="book"
    href="/concepts/hybrid-learning"
  >
    Understand the theory behind ATLAS.
  </Card>
</CardGroup>
