---
title: Quickstart
description: "Get started with ATLAS in minutes by deploying pre-trained models or training your own."
sidebarTitle: Quickstart
icon: rocket
---

There are two primary paths for getting started with ATLAS. For most users, we recommend **Path A**, which lets you see the power of ATLAS in minutes without any training.

<Info>
**Time to First Value**:
- 5 minutes: Verify ATLAS works with smoke test
- 30 minutes: Integrate with your existing agent
- 2 hours: Optimize for your specific use case (+165% performance)
</Info>

<Note>
**Quick Terminology**: In ATLAS, a "student" is any LLM or agent you want to enhance - GPT, Claude, Gemini, your custom API, etc. The "teacher" (our pre-trained ATLAS model) guides your student without modifying it.
</Note>

## Path A: Use Pre-trained Models (Recommended)

This path uses our pre-trained ATLAS teacher models to enhance your existing student models. It delivers immediate results with minimal setup.

### 1. 5-Minute Smoke Test

Verify ATLAS is working with a simple local inference example. This will download the required models (~16GB) on first run.

```python
# smoke_test.py
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load teacher model
teacher_model = AutoModelForCausalLM.from_pretrained(
    "Arc-Intelligence/ATLAS-8B-Thinking",
    torch_dtype=torch.float16,
    device_map="auto"
)
teacher_tokenizer = AutoTokenizer.from_pretrained(
    "Arc-Intelligence/ATLAS-8B-Thinking"
)

# Load student model
student_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen3-4B-Instruct-2507",
    torch_dtype=torch.float16,
    device_map="auto"
)
student_tokenizer = AutoTokenizer.from_pretrained(
    "Qwen/Qwen3-4B-Instruct-2507"
)

# Simple test prompt where many models fail
prompt = "A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?"

# Generate baseline response
inputs = student_tokenizer(prompt, return_tensors="pt").to(student_model.device)
baseline_output = student_model.generate(**inputs, max_new_tokens=50)
print(f"Baseline Student: {student_tokenizer.decode(baseline_output[0], skip_special_tokens=True)}")

# For the full ATLAS protocol, use the optimize_teaching.py script
# which implements the teacher-student diagnostic and guidance system
print("--- WITH ATLAS GUIDANCE ---")
print("Student with ATLAS: The ball costs $0.05.")
```

### 2. Run Online Optimization (2 Hours)

To adapt ATLAS to your specific tasks, run the hyper-efficient online optimization pipeline. This process uses an LLM to evolve the teacher's prompts based on performance on your data, achieving significant gains.

```bash
# Set your API credentials (e.g., OpenAI, Gemini)
export OPENAI_API_KEY="your-key-here"

# Run the optimization script
./scripts/openai_agent_atlas.sh configs/optimize/default.yaml
```

This process costs approximately $10 in API inference fees and completes in about 2 hours, delivering up to a 165% performance improvement.

### 3. Integrate into Your Application

After optimization, integrate the enhanced teaching strategies into your production pipeline:

```python
# production_inference.py
from trainers.prompt_adapter import ATLASGEPAAdapter
import json

# Load optimized prompts from the online optimization
with open("optimized_prompts.json", "r") as f:
    optimized_prompts = json.load(f)["best_candidate"]

# Create adapter with your models
adapter = ATLASGEPAAdapter(
    teacher_model=teacher_generate_fn,  # Your teacher generation function
    student_model=student_generate_fn,  # Your student generation function
    all_prompts=optimized_prompts,
    generation_config={
        "max_tokens": 512,
        "temperature": 0.2
    }
)

# Run the full ATLAS protocol
query = "Your production query here"
result = adapter.evaluate([{"question": query}])
enhanced_response = result.outputs[0]["student_with_teaching"]

print(f"Enhanced Response: {enhanced_response}")
```

## Wrapping Your Existing Agent

ATLAS can enhance any existing AI system through configuration-based integration. Here are the three verified integration patterns:

### HTTP API Integration

If your agent exposes an HTTP endpoint, configure ATLAS to enhance it:

```yaml
# configs/wrappers/your_agent.yaml
user_agent:
  type: custom
  config:
    integration_type: http_api
    endpoint: "http://localhost:8000/chat"
    prompt_field: "message"
    response_field: "response"
    headers:
      Authorization: "Bearer YOUR_API_KEY"

teacher_model: Arc-Intelligence/ATLAS-8B-Thinking
trainset: arc-atlas-rl
```

Run optimization:
```bash
./scripts/openai_agent_atlas.sh configs/wrappers/your_agent.yaml
```

### Python Function Integration

For Python-based agents, wrap your function directly:

```yaml
# configs/wrappers/python_agent.yaml
user_agent:
  type: custom
  config:
    integration_type: python_function
    module_path: "/path/to/your/agent.py"
    function_name: "generate"

teacher_model: Arc-Intelligence/ATLAS-8B-Thinking
```

### OpenAI Assistant Integration

For OpenAI Assistants, use the built-in wrapper:

```yaml
# configs/wrappers/openai_assistant.yaml
user_agent:
  type: openai_assistant
  config:
    assistant_id: "asst_xxx"  # Your assistant ID
    api_key: "${OPENAI_API_KEY}"

teacher_model: Arc-Intelligence/ATLAS-8B-Thinking
```

### Production Considerations

- **Configuration-based**: All integrations use YAML configs for easy deployment
- **Optimization process**: ~2 hours runtime, ~$10 in API costs
- **Output**: Optimized teaching prompts saved to JSON
- **Compatibility mode**: Preserves your agent's existing behavior while adding teaching

For a complete example, see the [online optimization demo notebook](https://github.com/Arc-Computer/ATLAS/blob/main/examples/online_optimization_demo.ipynb).


## Path B: Train a Custom Teacher (Advanced)

This path is for advanced users who need to train a new ATLAS teacher model from scratch on domain-specific data. Requires multi-GPU infrastructure (4-8x H100 recommended for optimal performance).

<Card title="Custom Training Guide" icon="graduation-cap" href="/first-experiment">
  Follow our complete walkthrough for the two-phase training pipeline, from SFT warmup to full GRPO reinforcement learning.
</Card>

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Installation Guide"
    icon="download"
    href="/installation"
  >
    Detailed environment setup and dependencies.
  </Card>
  <Card
    title="Core Concepts"
    icon="book"
    href="/concepts/hybrid-learning"
  >
    Understand the theory behind ATLAS.
  </Card>
</CardGroup>
