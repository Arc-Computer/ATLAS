---
title: Quickstart
description: "Get started with ATLAS in minutes by deploying pre-trained models or training your own."
sidebarTitle: Quickstart
icon: rocket
---

ATLAS is designed for production AI engineers. In under an hour you can plug the Teacher–Student loop into your existing agent, stream telemetry to your terminal, export training traces, and feed them into the GRPO trainer.

<Info>
**End-to-end flow:** Install SDK → Configure BYOA → Run Teacher/Student/Reward loop → Export traces → Train.
</Info>

## Step 1 — Install the runtime and set credentials

```bash
python -m pip install --upgrade arc-atlas
```

Create a `.env` (or use your secret manager) with the LLM keys you plan to call:

```bash
OPENAI_API_KEY=sk-...
# optional extras
GEMINI_API_KEY=...
AZURE_OPENAI_API_KEY=...
```

Load those variables before you orchestrate runs.

## Step 2 — Point ATLAS at your agent (Bring Your Own Agent, BYOA, in 5 minutes)

Atlas ships YAML templates for the three adapter families. Copy the closest example from the SDK (`configs/examples/`) and edit the `agent` block. For instance, to wrap a local HTTP service:

```yaml
# configs/my_http_agent.yaml
agent:
  type: http_api
  name: my-http-agent
  system_prompt: |
    You are the Atlas Student. Solve the task carefully and justify decisions.
  tools: []
  transport:
    base_url: http://localhost:8080/agent
    timeout_seconds: 60

student:
  max_plan_tokens: 1024
  max_step_tokens: 1024
  max_synthesis_tokens: 1024

teacher:
  llm:
    provider: openai
    model: gpt-4o-mini
    api_key_env: OPENAI_API_KEY
```

Swap the adapter for OpenAI (`type: openai`) or a local Python callable (`type: python`) if that fits your stack. The rest of the file—`student`, `teacher`, `rim`, `orchestration`—ships with sensible defaults. See [`SDK Configuration`](/sdk/configuration) for every field.

## Step 3 — Run the Teacher/Student/Reward loop with telemetry

```python
from atlas.core import run

result = run(
    task="Summarize the latest AI news",
    config_path="configs/my_http_agent.yaml",
    stream_progress=True,
)
```

When `stream_progress=True` and stdout is interactive, the `ConsoleTelemetryStreamer` auto-enables to print the accepted plan, retries, tool calls, and reward scores as they happen. Set `stream_progress=False` to silence streaming, or leave it unset and Atlas will auto-detect.

<Note>
Need persistence? Add a `storage:` block in your YAML (see below) so every session lands in Postgres for export.
</Note>

## Step 4 — Persist and export traces

Enable storage:

```yaml
storage:
  database_url: postgresql://atlas:atlas@localhost:5432/atlas
  min_connections: 1
  max_connections: 5
```

After a run (or a batch of runs) export the traces to JSONL:

```bash
atlas.export \
  --database-url postgresql://atlas:atlas@localhost:5432/atlas \
  --output traces/aime-batch.jsonl
```

<Note>
Ensure Postgres is running and reachable before exporting. You can launch it with `docker compose up -d postgres` (using the repo's compose file) or `brew services start postgresql`.
</Note>

Each JSONL record maps to the shared runtime schema (`task`, `plan`, per-step `reward` with nested judges, guidance history, validation, tool metadata). Preview a single record with `jq`:

```bash
jq '.' traces/aime-batch.jsonl | head
```

## Step 5 — Train or score with the runtime dataset

Point the core training stack at the exported file using the provided loader:

```yaml
# configs/data/runtime_traces.yaml
make_dataset_fn:
  _target_: custom_data.runtime_trace_data.get_runtime_trace_dataset
  export_path: traces/aime-batch.jsonl
  eval_split_ratio: 0.1
```

Now launch GRPO or a scoring job exactly as you would with any other dataset. The trainer sees the same reward structure that the runtime produced, so step-level improvements translate directly into policy updates. See [`Training Your Own Teacher`](/training/offline/grpo-training) for the full recipe.

## Optional — Advanced optimisation

Once the loop is running end-to-end, you can layer on additional optimisation strategies:

- **Prompt evolution (GEPA)** for rapid API-based improvements.
- **Custom judges** for domain-specific scoring.
- **Full GRPO retraining** when you need a bespoke teacher checkpoint.

Each of these uses the same exported traces, so you can adopt them incrementally as your workloads grow.

## Checklist

- [x] Installed `arc-atlas` and exported API keys
- [x] Wrapped the agent with a YAML config
- [x] Streamed telemetry for a real task
- [x] Enabled Postgres storage and exported JSONL traces
- [x] Consumed traces in the training stack

You now have the complete Atlas learning loop running—production telemetry into dataset exports, dataset exports into training, and training back into runtime performance.
