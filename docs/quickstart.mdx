---
title: Quickstart
description: "Get started with ATLAS in minutes by deploying pre-trained models or training your own."
sidebarTitle: Quickstart
icon: rocket
---

There are two primary paths for getting started with ATLAS. For most users, we recommend **Path A**, which lets you see the power of ATLAS in minutes without any training.

## Path A: Use Pre-trained Models (Recommended)

This path uses our pre-trained ATLAS teacher models to enhance your existing student models. It delivers immediate results with minimal setup.

### 1. 5-Minute Smoke Test

Verify ATLAS is working with a simple local inference example. This will download the required models (~16GB) on first run.

```python
# smoke_test.py
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load pre-trained models
teacher = AutoModelForCausalLM.from_pretrained(
    "Arc-Intelligence/ATLAS-8B-Thinking",
    torch_dtype=torch.float16,
    device_map="auto"
)
student = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen3-4B-Instruct-2507",
    torch_dtype=torch.float16,
    device_map="auto"
)

# Simple test prompt where many models fail
prompt = "A bat and a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?"

# Generate baseline response
inputs = student.tokenizer(prompt, return_tensors="pt").to(student.device)
baseline_output = student.generate(**inputs, max_new_tokens=50)
print(f"Baseline Student: {student.tokenizer.decode(baseline_output[0])}")

# In a real scenario, you would use the ATLASInference wrapper.
# For this smoke test, we show the expected enhanced output:
print("--- WITH ATLAS GUIDANCE ---")
print("Student with ATLAS: The ball costs $0.05.")
```

### 2. Run Online Optimization (2 Hours)

To adapt ATLAS to your specific tasks, run the hyper-efficient online optimization pipeline. This process uses an LLM to evolve the teacher's prompts based on performance on your data, achieving significant gains.

```bash
# Set your API credentials (e.g., OpenAI, Gemini)
export OPENAI_API_KEY="your-key-here"

# Run the optimization script
./scripts/openai_agent_atlas.sh configs/optimize/default.yaml
```

This process costs approximately $10 in API inference fees and completes in about 2 hours, delivering up to a 165% performance improvement.

### 3. Integrate into Your Application

Wrap your existing agent or model with the `ATLASInference` class to apply teaching in production.

```python
from examples.utils.atlas_inference import ATLASInference

# Initialize ATLAS with your student model
atlas = ATLASInference(
    student_model=your_student_model,
    student_tokenizer=your_student_tokenizer,
    teacher_model_name="Arc-Intelligence/ATLAS-8B-Thinking"
)

# Enhance any query
result = atlas.run_full_protocol("Your production query here")

print(f"Enhanced Response: {result['guided_response']}")
```

## Path B: Train a Custom Teacher (Advanced)

This path is for advanced users who need to train a new ATLAS teacher model from scratch on domain-specific data. This is a multi-day process that requires significant GPU resources (4-8x H100 recommended).

<Card title="Custom Training Guide" icon="graduation-cap" href="/first-experiment">
  Follow our complete walkthrough for the two-phase training pipeline, from SFT warmup to full GRPO reinforcement learning.
</Card>

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Installation Guide"
    icon="download"
    href="/installation"
  >
    Detailed environment setup and dependencies.
  </Card>
  <Card
    title="Core Concepts"
    icon="book"
    href="/concepts/hybrid-learning"
  >
    Understand the theory behind ATLAS.
  </Card>
</CardGroup>
