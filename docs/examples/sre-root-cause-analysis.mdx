---
title: "Case Study: SRE Root Cause Analysis"
description: Performance analysis of ATLAS on systematic debugging tasks in Kubernetes environments
sidebarTitle: SRE Case Study
icon: magnifying-glass
---

## Abstract

This case study examines ATLAS performance on Site Reliability Engineering (SRE) tasks, specifically root cause analysis in distributed Kubernetes environments. The system demonstrates systematic debugging improvements, reducing investigation time from 45 minutes to 3 minutes through iterative teaching protocols.

## Problem Formulation

Standard language models exhibit suboptimal performance on systematic debugging tasks due to:

- **Lack of structured investigation patterns** - Models default to surface-level diagnostics
- **Insufficient evidence gathering** - Premature hypothesis formation without comprehensive data collection
- **No learning transfer** - Previous incident resolutions don't inform future investigations
- **Inefficient exploration** - Redundant or irrelevant command sequences increase time-to-resolution

## Experimental Setup

**Task:** Diagnose service mesh configuration errors causing 503 errors in a Kubernetes cluster
**Data Source:** Scenarios from ITBench, providing reproducible incidents on Kubernetes environments
**Baseline Model:** Standard 8B parameter instruction-tuned LLM
**ATLAS Configuration:** Two-pass adaptive teaching protocol with 50-token diagnostic probe
**Evaluation Metric:** Correct root cause identification within resource constraints

## Results: Progressive Performance Improvement

<Tabs>
  <Tab title="Iteration 1: Baseline Failure">
    **Student's Flawed Approach:**
    ```bash
    kubectl get pods
    kubectl describe pod webapp-xxx
    kubectl logs webapp-xxx
    ```

    **Result:** Surface-level investigation, misses root cause in service mesh configuration

    **Performance:** 23% accuracy
  </Tab>

  <Tab title="Iteration 2: First Correction">
    **Teacher's Guidance:** "Check service endpoints before pod logs"

    **Improved Approach:**
    ```bash
    kubectl get endpoints
    istioctl proxy-config cluster webapp-xxx
    kubectl get virtualservice
    ```

    **Result:** Discovers service mesh misconfiguration

    **Performance:** 45% accuracy (+95% improvement)
  </Tab>

  <Tab title="Iteration 3: Skill Refinement">
    **Teacher's Guidance:** "Verify traffic flow through entire mesh"

    **Expert Approach:**
    ```bash
    istioctl analyze
    istioctl proxy-config routes webapp-xxx
    kubectl get peerauthentication -A
    ```

    **Result:** Identifies mTLS policy conflict

    **Performance:** 71% accuracy (+208% improvement)
  </Tab>

  <Tab title="Iteration 4: Expert Performance">
    **Final Optimized Approach:**

    Complete systematic investigation in correct order:
    1. Service mesh configuration analysis
    2. mTLS policy verification
    3. Traffic flow validation
    4. Root cause identification

    **Result:** Correct diagnosis in 3 minutes vs 45 minutes baseline

    **Performance:** Systematic investigation with correct root cause identification
  </Tab>
</Tabs>

## The Magic: How ATLAS Makes This Possible

### Three-Phase Learning Loop

<Steps>
  <Step title="Plan Phase">
    Student LLM proposes investigation strategy
    ```python
    "I'll check pod status and logs"  # Naive approach
    ```
  </Step>

  <Step title="Teach Phase">
    ATLAS teacher reviews and corrects the plan
    ```python
    "First verify service mesh configuration, then check traffic policies"
    ```
  </Step>

  <Step title="Execute Phase">
    Student applies corrected strategy and learns
    ```python
    # Executes improved investigation
    # Stores as reusable "Skill Capsule"
    ```
  </Step>
</Steps>

### Skill Capsules: Compounding Intelligence in Action

Each corrected procedure becomes a **Skill Capsule** - a reusable investigation pattern that improves future performance:

<CardGroup cols={2}>
  <Card title="Service Mesh Debug Capsule">
    Systematic Istio troubleshooting procedure learned from iterations 1-2
  </Card>
  <Card title="mTLS Conflict Capsule">
    Policy conflict detection pattern learned from iteration 3
  </Card>
  <Card title="Traffic Flow Capsule">
    End-to-end validation sequence learned from iteration 4
  </Card>
  <Card title="Root Cause Capsule">
    Evidence-based diagnosis framework from all iterations
  </Card>
</CardGroup>

## Real-World Impact

<CardGroup cols={3}>
  <Card title="3 min vs 45 min" icon="clock">
    **15x faster** incident resolution
  </Card>
  <Card title="Improved Accuracy" icon="chart-line">
    Systematic root cause identification
  </Card>
  <Card title="50% Fewer Tokens" icon="gauge">
    More efficient investigation paths
  </Card>
</CardGroup>

## Implementation Code

Here's how to implement this SRE enhancement in your environment:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from examples.utils.atlas_inference import ATLASInference

# Load ATLAS teacher trained on SRE procedures
teacher = AutoModelForCausalLM.from_pretrained(
    "Arc-Intelligence/ATLAS-8B-Thinking",
    trust_remote_code=True
)

# Your existing SRE bot or LLM
sre_model = AutoModelForCausalLM.from_pretrained(
    "your-sre-model",
    trust_remote_code=True
)

# Create ATLAS-enhanced SRE investigator
atlas_sre = ATLASInference(
    student_model=sre_model,
    teacher_model=teacher,
    probe_token_limit=50
)

# Incident investigation
incident = "Kubernetes service returning 503 errors"
result = atlas_sre.run_full_protocol(incident)

# Get expert investigation plan
investigation_plan = result["guided_response"]
```

## Try It Yourself

<CardGroup cols={2}>
  <Card title="Run the Demo" icon="play" href="/quickstart">
    Deploy the SRE configuration in your environment
  </Card>
  <Card title="View the Code" icon="github" href="https://github.com/Arc-Computer/ATLAS">
    Complete implementation on GitHub
  </Card>
</CardGroup>

## Why This Matters

Traditional approaches to improving LLM performance require:
- Massive retraining on domain-specific data
- Expensive fine-tuning for each use case
- Complex prompt engineering that breaks easily

ATLAS provides:
- **Immediate improvement** without retraining
- **Systematic skill acquisition** through teaching
- **Reusable knowledge** via Skill Capsules
- **Compounding returns** as skills build on each other

## Technical Deep Dive

<AccordionGroup>
  <Accordion title="How Skill Capsules Work">
    Skill Capsules are learned procedures stored as structured knowledge:

    ```python
    {
      "skill": "service_mesh_debug",
      "trigger": "503 errors in Kubernetes",
      "procedure": [
        "istioctl analyze",
        "check virtualservice configuration",
        "verify destination rules",
        "validate mTLS policies"
      ],
      "success_rate": 0.88
    }
    ```

    These capsules are retrieved and applied when similar problems arise.
  </Accordion>

  <Accordion title="The Adaptive Teaching Protocol">
    ATLAS uses a two-pass protocol:

    1. **Diagnostic Probe** (~50 tokens): Assess current capability
    2. **Targeted Correction** (~200 tokens): Provide precise guidance

    This minimal intervention approach ensures efficiency while maximizing improvement.
  </Accordion>

  <Accordion title="Online Optimization Process">
    The 165% gain in 2 hours happens through:

    1. **Reflective Mutation**: Automatic reward engineering
    2. **Policy Gradient Updates**: Continuous improvement
    3. **Skill Consolidation**: Converting lessons into reusable patterns

    Total cost: ~$10 in API calls
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={3}>
  <Card title="Deploy in Production" icon="rocket" href="/integration/production-patterns">
    Scale this approach across your SRE team
  </Card>
  <Card title="Custom Training" icon="graduation-cap" href="/training/offline/full-pipeline">
    Train ATLAS on your specific procedures
  </Card>
  <Card title="More Examples" icon="flask" href="/examples/math-reasoning">
    Explore other use cases
  </Card>
</CardGroup>