---
title: SDK Configuration Reference
description: Understand every block in an Atlas SDK YAML file so you can tailor the orchestrator to your agents.
sidebarTitle: Configuration
icon: settings
---

Atlas SDK configs are the control tower for runtime orchestration. Every key is validated by a Pydantic schema (`atlas-sdk/atlas/config/models.py`), so mistakes surface before the adaptive dual-agent reasoning loop—your agent paired with a verifying teacher—spins up.

<Note>
This page is a configuration reference. For adapter walkthroughs and orchestration concepts, see [`Bring Your Own Agent`](/sdk/adapters) and [`How Orchestration Works`](/sdk/orchestration).
</Note>

<Tip>
Keep `atlas.core.run(..., stream_progress=True)` enabled while tuning configs—the live event stream mirrors exactly what persists to storage and makes it easy to spot misconfigured blocks.
</Tip>

## Root Config Overview

| Field | Type / Default | Required? | Why it matters |
| --- | --- | --- | --- |
| `agent` | Adapter union (`http_api` \| `python` \| `openai`) | Yes | Connects the orchestrator to your underlying agent transport. |
| `teacher` | `TeacherConfig` | Yes | Defines the verifying teacher persona, LLM, and feedback limits. |
| `rim` | `RIMConfig` | Yes | Configures the reward ensemble that drives retries and adaptive feedback. |
| `student` | `StudentConfig` (token caps default to `2048`) | No | Controls your agent’s (student) prompts, tool usage, and token budgets. |
| `orchestration` | `OrchestrationConfig` (`max_retries=1`, `step_timeout_seconds=900`, `rim_guidance_tag="rim_feedback"`, `emit_intermediate_steps=true`) | No | Governs retries, timeouts, and telemetry emission. |
| `adaptive_teaching` | `AdaptiveTeachingConfig` (`enabled=true`) | No | Triage, probe, and lane-selection policy. |
| `storage` | `StorageConfig \| null` (default `null`) | No | Enables Postgres persistence for traces and learning memory. |
| `metadata` | `Dict[str, Any]` (default `{}`) | No | Free-form tags for analytics and logging. |

## Agent Block (`agent`)

This block wires the orchestrator to your agent. The schema is defined by `AdapterConfig` and its subclasses in `atlas-sdk/atlas/config/models.py:67-176`; extra keys are rejected.

### Common fields

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `type` | Enum: `http_api`, `python`, `openai` | Yes | Selects which adapter subclass will validate the rest of the block. |
| `name` | `str` | Yes | Appears in telemetry and logs; use a descriptive identifier per deployment. |
| `system_prompt` | `str` | Yes | Baseline persona text passed to your agent (the student). |
| `tools` | `List[ToolDefinition]` (default `[]`) | No | Register JSON-schema tool signatures; validation ensures required keys exist. |

### HTTP adapter (`type: http_api`)

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `transport.base_url` | `str` | Yes | Base endpoint for your service. |
| `transport.headers` | `Dict[str, str]` (default `{}`) | No | Inject auth or custom headers. |
| `transport.timeout_seconds` | `float` (default `60.0`) | No | Increase when downstream APIs are slow. |
| `transport.retry.attempts` | `int` (default `1`, bounded `1..5`) | No | Add resilience for flaky endpoints. |
| `transport.retry.backoff_seconds` | `float` (default `1.0`) | No | Control backoff between retry attempts. |
| `payload_template` | `Dict[str, Any]` (default `{}`) | No | Provide a skeleton payload with placeholders the runtime will fill. |
| `result_path` | `Sequence[str] \| null` | No | Extract a nested field from the response JSON. |

### Python adapter (`type: python`)

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `import_path` | `str` | Yes | Python module or package that exposes your callable. |
| `attribute` | `str \| null` | No | Specify the function/class name when the module exports multiple callables. |
| `working_directory` | `str \| null` | No | Run relative imports against a specific path. |
| `allow_generator` | `bool` (default `false`) | No | Enable when the callable yields streaming results. |
| `llm` | `LLMParameters \| null` | No | Supply metadata when the callable proxies an LLM (e.g., for telemetry). |

### OpenAI adapter (`type: openai`)

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `llm.provider` | `'openai'` or `'azure-openai'` | Yes | Adapter enforces OpenAI-compatible providers. |
| `llm.model` | `str` | Yes | Choose the underlying chat model. |
| `llm.api_key_env` | `str` (default `"OPENAI_API_KEY"`) | No | Point to a different environment variable. |
| `llm.temperature` | `float` (default `0.0`, range `0..2`) | No | Increase for more exploratory generations. |
| `llm.top_p` | `float \| null` | No | Apply nucleus sampling if desired. |
| `llm.max_output_tokens` | `int \| null` | No | Cap response length. |
| `llm.timeout_seconds` | `float` (default `60.0`) | No | Widen for long-running completions. |
| `llm.retry.attempts` | `int` (default `1`, bounded `1..5`) | No | Increase for transient API failures. |
| `response_format` | `Dict[str, Any] \| null` | No | Request JSON schema enforcement when the provider supports it. |

Example (from `atlas-sdk/configs/examples/openai_agent.yaml`):

```yaml
agent:
  type: openai
  name: example-openai-agent
  system_prompt: |
    You are an OpenAI model acting as the Atlas Student. Follow instructions carefully and respond with JSON when asked.
  tools: []
  llm:
    provider: openai
    model: gpt-5-mini
    api_key_env: OPENAI_API_KEY
    temperature: 0.2
    max_output_tokens: 2048
```

## Student Block (`student`)

Guides the student agent’s prompts and token budgets. When `prompts` is omitted, the runtime builds defaults from the agent `system_prompt`.

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `prompts` | `StudentPrompts \| null` | No | Override planner/executor/synthesizer prompt templates explicitly. |
| `prompt_guidance` | `Dict[str, str]` (default `{}`) | No | Supply reusable chunks merged into prompts per run. |
| `max_plan_tokens` | `int` (default `2048`) | No | Raise when plans are truncated. |
| `max_step_tokens` | `int` (default `2048`) | No | Increase for verbose tool output. |
| `max_synthesis_tokens` | `int` (default `2048`) | No | Allow longer final answers. |
| `tool_choice` | Literal `auto` \| `required` (default `auto`) | No | Force tool invocation on every step when governance demands it. |

Example (excerpt from `atlas-sdk/configs/examples/sdk_quickstart.yaml`):

```yaml
student:
  prompts:
    planner: |
      {base_prompt}

      Break the user's task into a short numbered plan.
    executor: |
      {base_prompt}

      Execute the current plan step. Show the work that led to your answer.
    synthesizer: |
      {base_prompt}

      Summarize the important findings from every step and deliver the final answer.
  max_plan_tokens: 1024
  max_step_tokens: 1024
  max_synthesis_tokens: 1024
  tool_choice: auto
```

## Teacher Block (`teacher`)

Defines the verifying teacher persona that validates plans, emits guidance, and certifies results.

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `llm` | `LLMParameters` | Yes | Choose the verifying teacher model (often stronger than the student agent). |
| `max_review_tokens` | `int \| null` (default `null`) | No | Cap plan-review responses. |
| `plan_cache_seconds` | `int` (default `300`) | No | Reuse approved plans for repeated task IDs. |
| `guidance_max_tokens` | `int \| null` | No | Limit per-step feedback length. |
| `validation_max_tokens` | `int \| null` | No | Cap the validation verdict. |
| `prompts` | `TeacherPrompts \| null` | No | Replace default reviewer prompts. |
| `prompt_guidance` | `Dict[str, str]` (default `{}`) | No | Inject reusable guidance fragments. |

## Orchestration Block (`orchestration`)

Controls retry semantics and telemetry.

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `max_retries` | `int` (default `1`, hard ceiling) | No | Set to `0` to disable retries entirely. |
| `step_timeout_seconds` | `float` (default `900.0`) | No | Lengthen for slow tools or external APIs. |
| `rim_guidance_tag` | `str` (default `"rim_feedback"`) | No | Change when your prompts expect a different insertion tag. |
| `emit_intermediate_steps` | `bool` (default `true`) | No | Toggle console/storage streaming of intermediate events. |

Example (from `atlas-sdk/configs/examples/sdk_quickstart.yaml`):

```yaml
orchestration:
  max_retries: 1
  step_timeout_seconds: 600
  rim_guidance_tag: rim_feedback
  emit_intermediate_steps: true
```

## Reward System Block (`rim`)

The Reward System evaluates each trajectory to decide whether to retry or accept the outcome.

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `small_model` | `LLMParameters` | Yes | Fast path judge; keep lightweight for latency-sensitive checks. |
| `large_model` | `LLMParameters` | Yes | Escalation judge invoked on disagreement. |
| `active_judges` | `Dict[str, bool]` (default `{"process": true, "helpfulness": true}`) | No | Toggle built-in dimensions or add custom judges. |
| `variance_threshold` | `float` (default `0.15`) | No | Lower to escalate disagreements sooner. |
| `uncertainty_threshold` | `float` (default `0.3`) | No | Raise to reduce escalations on ambiguous scores. |
| `parallel_workers` | `int` (default `4`, range `1..32`) | No | Tune concurrency to match judge model throughput. |
| `judge_prompt` | `str \| null` | No | Provide a rubric that defines success for your domain. |

Example of weighting judges:

```yaml
rim:
  small_model:
    provider: google
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 512
  large_model:
    provider: google
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 768
  active_judges:
    process: true
    helpfulness: true
    accuracy: false
  variance_threshold: 0.15
  uncertainty_threshold: 0.3
  judge_prompt: 'Reward runs that stay on brief, respect APIs, and deliver correct answers.'
```

See [`Reward Design`](/concepts/reward-design#reward-system-in-the-atlas-sdk) for guidance on composing ensembles and custom judges.

## Adaptive Teaching Block (`adaptive_teaching`)

Configures triage, probing, and lane routing for the adaptive dual-agent pair—your agent plus the verifying teacher (`atlas-sdk/atlas/config/models.py:185-227`).

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `enabled` | `bool` (default `true`) | No | Disable to bypass adaptive routing entirely. |
| `certify_first_run` | `bool` (default `true`) | No | Force first-time personas through `paired` certification. |
| `mode_override` | Literal \| `null` | No | Pin execution to `auto`, `paired`, `coach`, or `escalate`. |
| `triage_adapter` | `str \| null` | No | Reference a custom dossier builder. |
| `default_tags` | `List[str]` (default `[]`) | No | Apply default metadata to persona memories. |
| `probe.llm` | `LLMParameters \| null` | No | Override the capability probe model. |
| `probe.thresholds` | `auto=0.85`, `paired=0.65`, `coach=0.35` | No | Adjust lane cut-offs; order must satisfy `auto ≥ paired ≥ coach`. |
| `probe.fallback_mode` | Literal (`"paired"` default) | No | Lane chosen when the probe cannot decide. |
| `probe.evidence_limit` | `int` (default `6`, range `1..32`) | No | Limit how many supporting reasons the probe collects. |
| `probe.timeout_seconds` | `float` (default `15.0`) | No | Extend for slower models. |
| `reward.type` | Literal `rim` (default) \| `python` | No | Switch to a custom reward objective. |
| `reward.import_path` / `attribute` | `str` / `str` | Required when `type="python"` | Point at your custom scorer. |
| `reward.focus_prompt` | `str \| null` | No | Give the reward model an extra steer for this deployment. |

Example of forcing coach mode:

```yaml
adaptive_teaching:
  enabled: true
  mode_override: coach
  default_tags:
    - tenant:demo
    - domain:sre
  probe:
    thresholds:
      auto: 0.9
      paired: 0.7
      coach: 0.4
    fallback_mode: coach
```

## Storage Block (`storage`)

Controls Postgres persistence (`atlas-sdk/atlas/config/models.py:299-307`). Omit the block or set `storage: null` for ephemeral runs.

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `database_url` | `str` | Yes (when block present) | Point at your managed or local Postgres instance. |
| `min_connections` | `int` (default `1`) | No | Increase for burstier workloads. |
| `max_connections` | `int` (default `5`) | No | Upper bound for connection pool size. |
| `statement_timeout_seconds` | `float` (default `30.0`) | No | Abort long-running queries sooner. |

Tip: `atlas storage up` scaffolds a Docker Compose file with sensible defaults and exposes Postgres on `localhost:5433`.

## Metadata

| Parameter | Type / Default | Required? | Why adjust |
| --- | --- | --- | --- |
| `metadata` | `Dict[str, Any]` (default `{}`) | No | Attach labels consumed by your monitoring stack. |

<Warning>
Legacy configs may still include a `prompt_rewrite` block, but the runtime now rejects it (`atlas-sdk/atlas/core/__init__.py` raises a `ValueError`). Remove the block and rely on explicit `student.prompts` / `teacher.prompts` instead.
</Warning>

## Cheat Sheet

| Goal | Section to edit | Pointer |
| --- | --- | --- |
| Swap to Anthropic or Gemini | `agent` | Use the `http_api` adapter and supply the matching transport payload. |
| Tighten or loosen retries | `orchestration` + `rim` | Adjust `max_retries`, `variance_threshold`, and `uncertainty_threshold`. |
| Persist adaptive memories | `storage` | Add a Postgres URL or run `atlas storage up`. |
| Force a supervision lane | `adaptive_teaching` | Set `mode_override` to `auto`, `paired`, `coach`, or `escalate`. |
| Personalise prompts | `student.prompts` / `teacher.prompts` | Override templates or reuse `prompt_guidance`. |
| Enforce JSON output | `agent` (`response_format`) | Provide OpenAI-compatible schemas or swap to `http_api` with custom validation. |

## Validated Example (Quickstart)

This minimal config (from `atlas-sdk/configs/examples/sdk_quickstart.yaml`) exercises every major block and can be copied as a starting point:

```yaml
agent:
  type: openai
  name: sdk-quickstart-openai
  system_prompt: |
    You are the Atlas Student. Follow the task instructions carefully and keep responses concise.
  tools: []
  llm:
    provider: openai
    model: gpt-4o-mini
    api_key_env: OPENAI_API_KEY
    temperature: 0.0
    max_output_tokens: 768

student:
  max_plan_tokens: 1024
  max_step_tokens: 1024
  max_synthesis_tokens: 1024

teacher:
  llm:
    provider: openai
    model: gpt-4o-mini
    api_key_env: OPENAI_API_KEY
    temperature: 0.1
    max_output_tokens: 768
  plan_cache_seconds: 300

orchestration:
  max_retries: 1
  step_timeout_seconds: 600
  rim_guidance_tag: rim_feedback
  emit_intermediate_steps: true

rim:
  small_model:
    provider: google
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 512
  large_model:
    provider: google
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 768
  variance_threshold: 0.15
  uncertainty_threshold: 0.3

adaptive_teaching:
  enabled: true
  certify_first_run: true
  default_tags:
    - tenant:demo

storage: null
```

## Related Guides

- [`Bring Your Own Agent`](/sdk/adapters) — Adapter-specific tutorials.
- [`How Orchestration Works`](/sdk/orchestration) — Dual-agent control flow (student agent + verifying teacher) deep dive.
- [`Adaptive Runtime Guide`](/runtime_adaptive_flow) — Detailed explanation of probes, lanes, and certification.
- [`Reward Design`](/concepts/reward-design) — Building and tuning judge ensembles.
