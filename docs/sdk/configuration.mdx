---
title: SDK Configuration Reference
description: Understand every block in an Atlas SDK YAML file so you can tailor the orchestrator to your agents.
sidebarTitle: Configuration
icon: settings
---

Atlas SDK configs are the control tower for runtime orchestration. Each block in the YAML tells the Student, Teacher, and Reward System how to behave. Start with `configs/examples/openai_agent.yaml`, then explore the other templates (`http_agent.yaml`, `python_agent.yaml`) to match your deployment.

<Tip>
Run orchestration with `atlas.core.run(..., stream_progress=True)` to mirror every event in the terminal. The streamer depends on these same configuration blocks, so what you see in the console matches what persists to storage.
</Tip>

<Note>
All examples reference files in the Atlas SDK repo (`configs/examples/`). If you cloned the repo for the quickstart, you already have them.
</Note>


## Layout at a Glance

```yaml
agent:             # How to talk to your underlying model or service
student:           # Planner, executor, and synthesizer prompts/limits
teacher:           # Reviewer and validator settings
orchestration:     # Runtime policies like retries and timeouts
rim:               # Reward system (judges, arbiter, thresholds)
adaptive_teaching: # Triage adapter, capability probe, reward overrides
storage:           # (Optional) Postgres connection for trace persistence
```

Each section is restrictive by design—unexpected keys raise validation errors—so it’s easier to debug mistakes before the orchestrator spins up.

## Agent Configuration (`agent`)

This block defines how the orchestrator communicates with your agent.

| Adapter | Best for | Key fields |
|---------|----------|------------|
| `openai` | OpenAI or Azure OpenAI chat models | `llm` block (model, key env var, temperature, token limits) |
| `http_api` | Remote services behind an HTTP interface | `transport` (base URL, retry policy), `payload_template`, `result_path` |
| `python` | Local Python functions or callables | `import_path`, `attribute`, `working_directory`, optional `llm` metadata |

### OpenAI Adapter Example
```yaml
agent:
  type: openai
  name: sdk-quickstart-openai
  system_prompt: |
    You are the Atlas Student. Be concise and thorough.
  tools: []
  llm:
    provider: openai
    model: gpt-4o-mini
    api_key_env: OPENAI_API_KEY
    temperature: 0.0
    max_output_tokens: 768
```
<Tip>
Any non-OpenAI-compatible API (like Anthropic Claude) should use the `http_api` adapter until a dedicated integration is available.
</Tip>

See [`Bring Your Own Agent`](/sdk/adapters) for full walkthroughs of all three adapters.

## Student Configuration (`student`)

The Student block shapes planning, execution, and synthesis.

```yaml
student:
  prompts:
    planner: |
      {base_prompt}
      Draft a numbered plan as JSON.
    executor: |
      {base_prompt}
      Execute the step, showing intermediate reasoning.
    synthesizer: |
      {base_prompt}
      Combine results into the final answer.
  max_plan_tokens: 1024
  max_step_tokens: 1024
  max_synthesis_tokens: 1024
  tool_choice: auto
```

- **Prompts**: Templates that receive `{base_prompt}` from the agent’s system prompt. Atlas also ships opinionated defaults in `atlas.prompts.build_student_prompts`; override them by supplying explicit prompt strings, tweaking the base prompt, or calling the helper yourself.
- **Token limits**: Guardrails for LLM calls; increase them when steps are truncated.
- **`tool_choice`**: `auto` lets the Student call registered tools. Use `required` to force a tool call on every step.

## Teacher Configuration (`teacher`)

The Teacher reviews plans, validates outputs, and provides guidance.

```yaml
teacher:
  llm:
    provider: openai
    model: gpt-4o-mini
    api_key_env: OPENAI_API_KEY
    temperature: 0.1
    max_output_tokens: 768
  max_review_tokens: 1024
  plan_cache_seconds: 300
  guidance_max_tokens: 256
  validation_max_tokens: 256
```

- **LLM block**: Often mirrors the Student’s provider but can be a more powerful model for complex reviews.
- **`plan_cache_seconds`**: Caches an approved plan for a given task ID to avoid re-running reviews.
- **Guidance/validation caps**: Keep feedback concise; increase when you expect lengthy traces.
- **Prompts**: Teacher defaults come from `atlas.prompts.build_teacher_prompts`; override the prompts block to match your review style.

## Orchestration (`orchestration`)

These policies govern the runtime loop.

```yaml
orchestration:
  max_retries: 1
  step_timeout_seconds: 600
  rim_guidance_tag: rim_feedback
  emit_intermediate_steps: true
```

- **`max_retries`**: Default (and maximum) is 1. The orchestrator never retries the same step more than once.
- **`step_timeout_seconds`**: Per-step timeout; extend when calling slow tools or external APIs.
- **`rim_guidance_tag`**: The tag used to inject feedback from the Reward System back into prompts.
- **`emit_intermediate_steps`**: Keep `true` to stream events for logging and telemetry. Combine this with `stream_progress=True` in `atlas.core.run` to see the Teacher/Student loop live.

## Reward System (the `rim` block)

The Reward System scores each attempt so the orchestrator knows whether to accept an answer or trigger a retry. The YAML block is named `rim` for compatibility with the core training engine.

```yaml
rim:
  small_model:
    provider: google
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 512
  large_model:
    provider: google
    model: gemini/gemini-2.5-flash
    api_key_env: GEMINI_API_KEY
    max_output_tokens: 768
  judge_prompt: 'Reward runs that follow the plan, stay safe, and finish the task.'
  active_judges:
    process: true
    helpfulness: true
  variance_threshold: 0.15
  uncertainty_threshold: 0.3
```

- **`judge_prompt`**: Steer evaluation criteria toward specific domain objectives. The evaluator includes this prompt when deriving principles and scoring the trajectory.
- **Judge toggles**: Enable or disable built-in judges through `active_judges`. Custom judges can be added by extending `atlas.evaluation.judges`.
- **Escalation models**: `small_model` handles the fast path; `large_model` resolves disagreements when variance or uncertainty exceed the configured thresholds.
- **Retry behaviour**: The orchestrator retries when the aggregated score falls below `0.6` (built-in default). Adjust `max_retries` in the orchestration block to cap how many attempts are made.

**Defining domain-agnostic objectives:**
The RIM block lets you express generic quality criteria (like security guardrails, compliance checks, or output correctness) in natural language through judge prompts—no model training required. Each judge evaluates a dimension (e.g., "Does this response avoid prompt injection?", "Is the reasoning process sound?") and the system reconciles multiple judge opinions via ensemble and escalation. Importantly, this scoring loop never modifies model weights; it operates purely at inference time to provide feedback signals that steer behavior and inform retry decisions. Think of RIM as an evaluation and governance layer, not a training mechanism. See [`Reward Design`](/concepts/reward-design) for examples of how to define objectives through judge prompts.

Learn more in [`Reward Design`](/concepts/reward-design#reward-system-in-the-atlas-sdk).

## Adaptive Teaching (`adaptive_teaching`)

This block powers the triage → probe → adaptive-mode controller. Leave it at the defaults to inherit the out-of-the-box behaviour or customise it to align with your governance rules.

```yaml
adaptive_teaching:
  enabled: true
  certify_first_run: true
  mode_override: null            # Force a lane when governance requires it
  triage_adapter: atlas.utils.triage:default_build_dossier
  default_tags:
    - tenant:demo
    - domain:sre
  probe:
    thresholds:
      auto: 0.85
      paired: 0.65
      coach: 0.40
    fallback_mode: coach
    evidence_limit: 6
    timeout_seconds: 15
  reward:
    type: rim                     # or "python" for a custom objective
    focus_prompt: null
```

- **`enabled`** / **`mode_override`**: Globally toggle the adaptive controller or pin the runtime to `auto`, `paired`, `coach`, or `escalate`.
- **`certify_first_run`**: When `true`, the first time a persona fingerprint appears it is forced through a `paired` certification and the verdict is cached.
- **`triage_adapter`**: A dotted path to a Python callable that returns a `TriageDossier`. Use `atlas triage init --domain <code|sre|support>` to scaffold a custom adapter.
- **`default_tags`**: Labels automatically attached to persona memories and adaptive telemetry.
- **`probe`**: Configures the capability probe LLM. Adjust the confidence thresholds, fallback behaviour, evidence length, or timeout. Set `probe.llm` if you want to override the default Gemini model.
- **`reward`**: Override the reward objective. Set `type: rim` for the built-in evaluator or `type: python` to point at a custom scorer via `import_path`/`attribute`. Use `focus_prompt` to steer the evaluation toward specific quality criteria—the evaluator includes this prompt when deriving principles and scoring the trajectory.

See the [Adaptive Runtime Guide](/runtime_adaptive_flow) for a walkthrough of how these fields shape triage, probing, and lane decisions.

## Storage (`storage`)

Postgres persistence for traces and learning memory—**required for continual improvement across runs**.

```yaml
storage:
  database_url: postgresql://localhost:5432/atlas
  min_connections: 1
  max_connections: 5
  statement_timeout_seconds: 30
```

**How storage enables learning:**
Without storage, each run is isolated—no memory persists between sessions. With storage enabled, ATLAS remembers what guidance worked on past tasks and retrieves those successful patterns for similar future runs. This persistent memory drives token efficiency gains and faster resolution on repeated scenarios. The system learns at inference time by recalling helpful strategies, not by modifying model weights.

**You control where data lives:**
When enabled, all traces write only to the Postgres database you provide via `database_url`—your self-hosted, cloud-managed, or local instance. ATLAS never operates its own data store or intermediary sink. You retain complete ownership and access control. Leave `storage: null` to run in ephemeral mode (no persistence), but note that this disables cross-session learning. Enable storage when you want continual gains:

```bash
arc-atlas \
  --database-url postgresql://localhost:5432/atlas \
  --output traces/runtime.jsonl \
  --trajectory-event-limit 500 \
  --status succeeded
```

Need a local instance quickly? Run `atlas storage up` to generate a Docker Compose file and start Postgres with sensible defaults.

## Persona prompts & guidance

Atlas derives persona text by combining the adapter’s `system_prompt` with helper templates in `atlas.prompts`. Customize behaviour by:

- Providing explicit strings under `student.prompts` and `teacher.prompts`.
- Adjusting the adapter’s base `system_prompt`.
- Calling `atlas.prompts.build_student_prompts` / `build_teacher_prompts` in your own tooling before handing prompts to the config.
- Supplying optional `prompt_guidance` dicts (per persona) when you need to inject structured hints that the runtime merges into prompts at execution time.

## Cheat Sheet

| Goal | Section to edit | Quick pointer |
|------|-----------------|---------------|
| Swap to Anthropic via HTTP | `agent` | Use the `http_api` adapter and point `transport.base_url` to your service. |
| Increase reasoning depth | `student` and `teacher` | Raise the `max_..._tokens` limits for the planner, executor, or guidance. | 
| Steer adaptive routing | `adaptive_teaching` | Tweak probe thresholds, default tags, or set `mode_override`. |
| Persist sessions | `storage` | Provide a Postgres URL or run `atlas storage up` and export with `arc-atlas`. |
| Tighten the quality bar | `rim` | Lower `variance_threshold` / `uncertainty_threshold` or disable lenient judges in `active_judges`. |
| Personalize prompts | `student.prompts` / `teacher.prompts` | Override the templates directly or use `atlas.prompts` helpers. |

## Next Steps

- Walk through the runtime loop in [`How Orchestration Works`](/sdk/orchestration) and keep the [`Adaptive Runtime Guide`](/runtime_adaptive_flow) nearby for controller tuning.
- Choose the right connector in [`Bring Your Own Agent`](/sdk/adapters).
- See how runtime roles compare to training in [`Student & Teacher Roles`](/sdk/student-teacher-roles).
