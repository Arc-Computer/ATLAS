---
title: "Export Runtime Traces"
description: Persist Atlas SDK sessions to JSONL so you can feed training pipelines without manual munging.
sidebarTitle: Export Traces
icon: database
---

The Atlas SDK can persist every orchestration session, including per-step rewards, guidance history, and tool usage. Use the `arc-atlas` CLI (or `python -m atlas.cli.export`) to convert those records into JSONL files that plug directly into the training stack (`load_runtime_traces`, `sessions_to_rl_records`).

## 1. Enable Postgres persistence

Add a `storage` block to your SDK config:

```yaml
storage:
  database_url: postgresql://atlas:atlas@localhost:5432/atlas
  min_connections: 1
  max_connections: 5
  statement_timeout_seconds: 30
```

Run your tasks with `atlas.core.run(..., stream_progress=True)` as usual. Each session, step result, and intermediate event is written to Postgres.

## 2. Export to JSONL

```bash
arc-atlas \
  --database-url postgresql://atlas:atlas@localhost:5432/atlas \
  --output traces/my-session.jsonl \
  --trajectory-event-limit 500 \
  --status succeeded \
  --limit 50
```

<Note>
Start Postgres before exporting (e.g., `docker compose up -d postgres` or `brew services start postgresql`) so the CLI can connect successfully.
</Note>

<Tip>
If another tool owns the `atlas` command on your system, run the exporter with `python -m atlas.cli.export ...` or adjust `PATH` so `arc-atlas` resolves first.
</Tip>

### Optional filters

- `--session-id 42` (repeatable) exports specific sessions.
- `--limit 25` / `--offset 25` page through recent sessions.
- `--status succeeded --status failed` filters on runtime completion state.
- `--trajectory-event-limit 200` caps the number of intermediate telemetry events embedded per session.
- `--batch-size 20` controls how many sessions are fetched per query when walking large tables.

The exporter writes one JSON object per line. Each record aligns with `AtlasSessionTrace`:

```jsonc
{
  "task": "Summarize the latest Atlas SDK updates",
  "final_answer": "...",
  "adaptive_summary": {
    "adaptive_mode": "coach",
    "confidence": 0.58,
    "certification_run": false,
    "probe": {
      "mode": "coach",
      "confidence": 0.55,
      "evidence": ["persona_helpful_ratio=0.62", "risk_high_severity"]
    },
    "mode_history": [
      {"mode": "paired", "confidence": 0.71, "certification": true},
      {"mode": "coach", "confidence": 0.55}
    ]
  },
  "triage_dossier": {
    "task": "Summarize the latest Atlas SDK updates",
    "summary": "Capture highlights for stakeholders.",
    "risks": [{"category": "quality", "description": "Customer-facing copy", "severity": "moderate"}],
    "signals": [{"name": "tenant", "value": "demo"}],
    "tags": ["tenant:demo", "domain:sre"]
  },
  "plan": {"steps": [{"id": 1, "description": "Collect release notes"}, {"id": 2, "description": "Draft summary"}]},
  "steps": [
    {
      "step_id": 1,
      "description": "Collect release notes",
      "trace": "HUMAN: ...",
      "output": "...",
      "reward": {
        "score": 0.92,
        "judges": [
          {"identifier": "process", "score": 0.91, "rationale": "..."}
        ]
      },
      "guidance": ["Cite the release date."],
      "validation": {"valid": true, "rationale": "Complete"},
      "tool": "web_search",
      "tool_params": {"query": "Atlas SDK release notes"},
      "artifacts": {"sources": ["https://..."]},
      "deliverable": {"notes": ["https://..."]}
    }
  ],
  "session_reward": {
    "score": 0.88,
    "uncertainty": 0.07,
    "judges": [
      {"identifier": "process", "score": 0.90, "rationale": "..."}
    ]
  },
  "reward_summary": {"score": 0.88},
  "personas_used": [
    {"persona": "planner", "instruction": "Focus on customer tone", "source": "memory"}
  ],
  "persona_updates": {
    "new_candidates": [
      {"persona": "planner", "instruction": "Mention adaptive modes", "tags": ["tenant:demo"]}
    ]
  },
  "session_metadata": {"batch": "aime-2025"}
}
```

> **Tip:** Compress large exports with `xz` or `gzip`â€”the loader streams line-by-line, so you can decompress on the fly if desired.

Use `adaptive_summary` to audit routing choices, probe evidence, and certification status; `triage_dossier` captures the structured context that informed the decision; `personas_used` and `persona_updates` show how memory evolved during the run. Each step also carries structured `artifacts` captured during execution and a `deliverable` payload that mirrors what the Student hands back to downstream systems.

## 3. Feed the training stack

```python
from trainers.runtime_dataset import load_runtime_traces, sessions_to_rl_records

sessions = load_runtime_traces("traces/my-session.jsonl")
records = sessions_to_rl_records(sessions)
```

Or use the Hydra shortcut (`configs/data/runtime_traces.yaml`) described in the top-level quickstart. The exported schema matches the training adapters, so no custom glue code is required.

## Troubleshooting

| Error | Likely cause | Fix |
|-------|--------------|-----|
| `database connection refused` | Postgres URL unreachable | Verify host/port, ensure server is running. |
| Empty JSONL file | No sessions stored | Confirm `storage` block is enabled and runs completed successfully. |
| Missing rewards in JSON | Judges disabled | Ensure your `rim` block activates the judges you expect. |

With the exporter in place you can schedule nightly runs, collect batches of traces, and continuously fine-tune the teacher without manual wrangling.
