---
title: "SDK Quickstart: Run Your First Task"
description: Launch the Atlas SDK runtime, run your first task, and understand how the dual-agent loop (your student agent + verifying teacher) orchestrates work.
sidebarTitle: SDK Quickstart
icon: play
---

<div align="center">
  <video
    controls
    width="900"
    style={{borderRadius: '12px'}}
    src="/images/Atlas.sdk-high.mp4"
  >
  </video>
  <p><em>Watch: Complete SDK setup walkthrough—install, configure, and see real performance gains in 2 minutes.</em></p>
</div>

This guide provides the fastest path to running the Atlas SDK. Install the packaged runtime, point it at your agent, and execute your first task in a few commands—all while the adaptive runtime decides how much supervision each request needs.

<Note>
**Beta notice:** The Atlas SDK runtime is in beta. APIs and configuration keys may evolve—check release notes before upgrading.
</Note>

## Prerequisites

<Note>
Install the SDK directly from PyPI:
</Note>

1. **Install and upgrade the SDK**
   ```bash
   python -m pip install --upgrade arc-atlas
   ```
   <Tip>
   Working inside a virtual environment? Activate it first, then install the package.
   </Tip>
2. **Store your LLM credentials**
   ```bash
   export OPENAI_API_KEY="sk-your-key"
   ```
   <Tip>
   Using Azure OpenAI? Set the usual environment variables (`AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`) and update the config’s provider/model entries before running.
   </Tip>
3. **Use a modern version of Python.** The SDK is tested with Python 3.10 and newer (the repo is developed with Python 3.13).

<Note>
We recommend keeping credentials in a `.env` file and loading them with `dotenv` or your process manager so they never land in shell history.
</Note>

## Step 1 – Run the Quickstart Task

Atlas now ships with an autodiscovery CLI so you can validate your environment before touching Python.

<div align="center">
  <img src="/images/adaptive-runtime.png" alt="Atlas SDK adaptive runtime flow diagram showing triage, probe, and lane routing" width="900" />
  <p><em>The adaptive runtime probes capability and routes every task into the right lane before the dual-agent loop (student + verifying teacher) executes.</em></p>
</div>

### Option A – CLI Autodiscovery (recommended for new stacks)

```bash
pip install arc-atlas
atlas env init --task "Summarize the latest AI news"
atlas run --config .atlas/generated_config.yaml --task "Summarize the latest AI news"
```

- `atlas env init` scans for `@atlas.environment` / `@atlas.agent` decorators or factory functions, loads `.env`, and writes `.atlas/discover.json`, `.atlas/generated_factories.py`, and `.atlas/generated_config.yaml`.
- `atlas run --config` loads the generated config, verifies module hashes, streams telemetry into `.atlas/runs/`, and injects learning playbooks when available.
- Need to exercise the full orchestrator? Point `atlas run --config configs/examples/openai_agent.yaml --task "..."` at a config file to bypass discovery entirely.

### Option B – Python API (direct invocation)

If you already have a config checked into source control, the standard `atlas.core.run` entry point still works:

```python
from atlas.core import run

result = run(
    task="Summarize the latest AI news",
    config_path="configs/examples/openai_agent.yaml",
    stream_progress=True,
)
print(result.final_answer)
```

<Info>
Run it inline if you prefer to avoid creating a file:
```bash
python -c "from atlas.core import run; result = run(task='Summarize the latest AI news', config_path='configs/examples/openai_agent.yaml', stream_progress=True); print(result.final_answer)"
```
</Info>

In both flows you should see an adaptive summary headline in the console stream (for example, `Adaptive: mode=coach confidence=0.58 certification=True`) followed by the plan–execute–synthesize loop. `atlas.runtime.telemetry.ConsoleTelemetryStreamer` auto-enables when stdout is a TTY; override with `stream_progress=True/False`.

Need a local Postgres instance? Run `atlas init` to scaffold and launch the Docker Postgres stack. Skip this step if you prefer ephemeral runs.

<Info>
**Want to see adaptive learning in action?** Check out the [Adaptive Tool Use example](/examples/adaptive-tool-use) showing a LangGraph agent learning efficient MCP tool usage across 25 tasks, demonstrating 30-40% reduction in tool calls.
</Info>

### Bring Your Own Agent

Atlas wraps any agent that exposes an OpenAI-compatible API, HTTP endpoint, or Python callable. Three adapter types are available:

- **OpenAI adapter** - For GPT, Claude via OpenAI-compatible APIs
- **HTTP adapter** - For microservices, serverless functions
- **Python adapter** - For LangGraph, local callables, custom agents

See the [Agent Adapters guide](/sdk/adapters) for complete configuration options and examples.

## What Just Happened?

Think of `atlas.core.run` as a project manager who never gets tired—now fronted by an adaptive controller:

- **Triage & probe** – a triage adapter builds context, the capability probe scores confidence, and the runtime picks a lane.
- **Configure** – the YAML tells the orchestrator which agent to call and how the Student/Teacher/Reward System trio should behave.
- **Plan** – the Student drafts a step-by-step approach when a stepwise lane is chosen; in single-shot lanes the plan collapses to one step.
- **Review** – the Teacher approves or tweaks the plan (or just inspects the final answer in `paired` mode).
- **Execute** – each step runs with lane-specific guidance, validation, and retries.
- **Evaluate** – the Reward System scores the work, deciding whether to reuse guidance and how to update persona memories.

## Configuration Breakdown

The `openai_agent.yaml` config defines the runtime behavior. Here’s a high-level look at the key sections:

- **`agent`**: Specifies the agent to run the task. The quickstart uses the OpenAI adapter with `gpt-5-mini` and no tools, requiring only an `OPENAI_API_KEY`.
- **`student`**: Configures the planner, executor, and synthesizer roles with their respective prompts and token limits.
- **`teacher`**: Defines the review and guidance agent, which also has its own model and token budget.
- **`orchestration`**: Sets runtime parameters like the number of retries (default: 1) and step timeouts.
- **`rim`** (Reward System): Defines the judges and arbiter that score the final answer for quality and helpfulness. This score determines if a retry is needed.
- **`storage`**: Point at Postgres to persist episodes; remove the block or set it to `null` for in-memory experiments.
- **`student.prompts` / `teacher.prompts`**: Optional overrides. Atlas derives persona text from `atlas.prompts`; customize behaviour by editing these prompt blocks directly.

To add tools, enable persistence, or use a different agent, switch the `config_path` to another template in `configs/examples/` (e.g., `http_agent.yaml`, `python_agent.yaml`) and see the `SDK Configuration` reference for details.

## Troubleshooting Checklist

- **Missing API key** – ensure `OPENAI_API_KEY` (or Azure equivalents) are exported in the same shell.
- **Time spent downloading dependencies** – editable installs pull in `litellm`, `httpx`, and friends on the first run; subsequent runs are instant.
- **Model limits** – bump `max_output_tokens` in the config if your summaries get truncated.

## Next Steps

<CardGroup cols="2">
  <Card title="Adaptive Tool Use" icon="wrench" href="/examples/adaptive-tool-use">
    See measurable learning with MCP tool integration
  </Card>
  <Card title="Agent Adapters" icon="plug" href="/sdk/adapters">
    Connect your own agent framework
  </Card>
  <Card title="Configuration Guide" icon="sliders" href="/sdk/configuration">
    Fine-tune orchestration and learning parameters
  </Card>
  <Card title="Export Training Data" icon="database" href="/sdk/export-traces">
    Persist sessions and build datasets for offline training
  </Card>
</CardGroup>
